{
 "cells": [
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Standard library imports\n",
    "import os\n",
    "import pickle\n",
    "import random\n",
    "from collections import defaultdict, deque\n",
    "from pathlib import Path\n",
    "\n",
    "# Third-party library imports\n",
    "import matplotlib\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.animation import FuncAnimation\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from PIL import Image, ImageTk\n",
    "from matplotlib.backends.backend_tkagg import FigureCanvasTkAgg\n",
    "from tensorflow.keras.layers import Conv2D, Dense, Dropout, Flatten, MaxPooling2D, Input, Layer\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import Callback\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# Local application imports\n",
    "import tkinter as tk\n",
    "from tkinter import filedialog\n",
    "from tkinter import messagebox, ttk"
   ],
   "id": "592a6484282bade2"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "sns.set()",
   "id": "fd1b37a0b6515251"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Define KAN CNN Model",
   "id": "7c193081e4a60708"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "class BSplineReLU(Layer):\n",
    "    def __init__(self, **kwargs):\n",
    "        super(BSplineReLU, self).__init__(**kwargs)\n",
    "        self.control_points = self.add_weight(name='control_points', shape=(4,), initializer='ones', trainable=True)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        # Example logic to incorporate B-spline control points into ReLU (simplified for illustration)\n",
    "        relu_output = tf.nn.relu(inputs)\n",
    "        spline_output = relu_output * self.control_points[0] + (1 - relu_output) * self.control_points[1]\n",
    "        return spline_output\n",
    "\n",
    "\n",
    "# Custom KAN layer\n",
    "class KANConv2D(Layer):\n",
    "    def __init__(self, filters, kernel_size, **kwargs):\n",
    "        super(KANConv2D, self).__init__(**kwargs)\n",
    "        self.conv = Conv2D(filters, kernel_size, **kwargs)\n",
    "        self.b_spline_relu = BSplineReLU()\n",
    "\n",
    "    def call(self, inputs):\n",
    "        x = self.conv(inputs)\n",
    "        return self.b_spline_relu(x)\n",
    "\n",
    "\n",
    "# KAN model\n",
    "def KANCNN(input_shape, num_classes):\n",
    "    inputs = Input(shape=input_shape)\n",
    "    x = KANConv2D(32, (3, 3))(inputs)\n",
    "    x = MaxPooling2D((2, 2))(x)\n",
    "    x = KANConv2D(64, (3, 3))(x)\n",
    "    x = MaxPooling2D((2, 2))(x)\n",
    "    x = KANConv2D(128, (3, 3))(x)\n",
    "    x = MaxPooling2D((2, 2))(x)\n",
    "    x = Flatten()(x)\n",
    "    x = Dense(512)(x)\n",
    "    x = BSplineReLU()(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    outputs = Dense(num_classes, activation='softmax')(x)\n",
    "    model = Model(inputs, outputs)\n",
    "    return model"
   ],
   "id": "d283f183ac863977"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def update_plot(fig, epoch, train_losses, val_losses, lrs, weights_stats):\n",
    "    plt.clf()\n",
    "\n",
    "    # Plot training and validation loss\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(range(1, len(train_losses) + 1), train_losses, label='Train Loss')\n",
    "    plt.plot(range(1, len(val_losses) + 1), val_losses, label='Validation Loss')\n",
    "    plt.plot(range(1, len(lrs) + 1), lrs, label='Learning Rate')\n",
    "    plt.title('Training and Validation Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss / Learning Rate')\n",
    "    plt.legend()\n",
    "\n",
    "    # Plot weight statistics\n",
    "    plt.subplot(1, 2, 2)\n",
    "    if len(weights_stats) > 0:\n",
    "        for layer_idx in range(len(weights_stats[0])):\n",
    "            means = [stat[layer_idx]['mean'] for stat in weights_stats]\n",
    "            stds = [stat[layer_idx]['std'] for stat in weights_stats]\n",
    "            plt.plot(range(1, len(weights_stats) + 1), means, label=f'Weights Layer {layer_idx} Mean')\n",
    "            plt.fill_between(range(1, len(weights_stats) + 1), np.array(means) - np.array(stds),\n",
    "                             np.array(means) + np.array(stds), alpha=0.2)\n",
    "\n",
    "    plt.title('Weights Mean and Std Dev Over Epochs')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Value')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.suptitle(f'Epoch {epoch + 1}')\n",
    "    plt.pause(0.1)\n",
    "    fig.canvas.draw()\n",
    "\n",
    "\n",
    "# Custom training loop\n",
    "def train_model(data_path: str = './data', epochs: int = 100, use_kan: bool = True):\n",
    "    # Define the paths\n",
    "    train_dir = f'{data_path}/train'\n",
    "    valid_dir = f'{data_path}/valid'\n",
    "    test_dir = f'{data_path}/test'\n",
    "\n",
    "    # Load the CSV file\n",
    "    dataset_csv = pd.read_csv(f'{data_path}/cards.csv')\n",
    "\n",
    "    # Create ImageDataGenerator for loading and augmenting images\n",
    "    train_datagen = ImageDataGenerator(rescale=1. / 255)\n",
    "    valid_datagen = ImageDataGenerator(rescale=1. / 255)\n",
    "    test_datagen = ImageDataGenerator(rescale=1. / 255)\n",
    "\n",
    "    train_generator = train_datagen.flow_from_directory(\n",
    "        train_dir,\n",
    "        target_size=(224, 224),\n",
    "        batch_size=32,\n",
    "        class_mode='categorical'\n",
    "    )\n",
    "\n",
    "    valid_generator = valid_datagen.flow_from_directory(\n",
    "        valid_dir,\n",
    "        target_size=(224, 224),\n",
    "        batch_size=32,\n",
    "        class_mode='categorical'\n",
    "    )\n",
    "\n",
    "    test_generator = test_datagen.flow_from_directory(\n",
    "        test_dir,\n",
    "        target_size=(224, 224),\n",
    "        batch_size=32,\n",
    "        class_mode='categorical'\n",
    "    )\n",
    "\n",
    "    model_path = f'./models/{epochs}_model.h5'\n",
    "    input_shape = (224, 224, 3)\n",
    "    num_classes = 53  # 53 classes for 53 cards\n",
    "\n",
    "    if Path(model_path).exists():\n",
    "        model = KANCNN(input_shape, num_classes) if use_kan else Sequential([\n",
    "            Conv2D(32, (3, 3), activation='relu', input_shape=input_shape),\n",
    "            MaxPooling2D((2, 2)),\n",
    "            Conv2D(64, (3, 3), activation='relu'),\n",
    "            MaxPooling2D((2, 2)),\n",
    "            Conv2D(128, (3, 3), activation='relu'),\n",
    "            MaxPooling2D((2, 2)),\n",
    "            Flatten(),\n",
    "            Dense(512, activation='relu'),\n",
    "            Dropout(0.5),\n",
    "            Dense(num_classes, activation='softmax')\n",
    "        ])\n",
    "        model.compile(optimizer='adam',\n",
    "                      loss='categorical_crossentropy',\n",
    "                      metrics=['accuracy'])\n",
    "        model.load_weights(model_path)  # Load your trained model weights\n",
    "        return model\n",
    "    else:\n",
    "        model = KANCNN(input_shape, num_classes) if use_kan else Sequential([\n",
    "            Conv2D(32, (3, 3), activation='relu', input_shape=input_shape),\n",
    "            MaxPooling2D((2, 2)),\n",
    "            Conv2D(64, (3, 3), activation='relu'),\n",
    "            MaxPooling2D((2, 2)),\n",
    "            Conv2D(128, (3, 3), activation='relu'),\n",
    "            MaxPooling2D((2, 2)),\n",
    "            Flatten(),\n",
    "            Dense(512, activation='relu'),\n",
    "            Dropout(0.5),\n",
    "            Dense(num_classes, activation='softmax')\n",
    "        ])\n",
    "\n",
    "        model.compile(optimizer='adam',\n",
    "                      loss='categorical_crossentropy',\n",
    "                      metrics=['accuracy'])\n",
    "\n",
    "        # Custom training loop to update B-spline parameters and weights\n",
    "        train_losses = []\n",
    "        val_losses = []\n",
    "        lrs = []\n",
    "        control_points_values = []\n",
    "        weights_stats = []\n",
    "\n",
    "        fig = plt.figure(figsize=(16, 6))\n",
    "        for epoch in range(epochs):\n",
    "            print(f'Epoch {epoch + 1}/{epochs}')\n",
    "            history = model.fit(train_generator, validation_data=valid_generator, epochs=1)\n",
    "\n",
    "            train_loss = history.history['loss'][0]\n",
    "            val_loss = history.history['val_loss'][0]\n",
    "            lr = model.optimizer.learning_rate.numpy()\n",
    "\n",
    "            train_losses.append(train_loss)\n",
    "            val_losses.append(val_loss)\n",
    "            lrs.append(lr)\n",
    "\n",
    "            # Collect control points and weight statistics\n",
    "            control_points = []\n",
    "            layer_weights_stats = []\n",
    "            for layer in model.layers:\n",
    "                if isinstance(layer, BSplineReLU):\n",
    "                    control_points.append(layer.control_points.numpy())\n",
    "                if isinstance(layer, KANConv2D):\n",
    "                    weights = layer.conv.get_weights()[0]\n",
    "                    mean = np.mean(weights)\n",
    "                    std = np.std(weights)\n",
    "                    layer_weights_stats.append({'mean': mean, 'std': std})\n",
    "\n",
    "            control_points_values.append(control_points)\n",
    "            weights_stats.append(layer_weights_stats)\n",
    "\n",
    "            update_plot(fig, epoch, train_losses, val_losses, lrs, weights_stats)\n",
    "\n",
    "            # Update B-spline parameters and control points\n",
    "            for layer in model.layers:\n",
    "                if isinstance(layer, KANConv2D) or isinstance(layer, BSplineReLU):\n",
    "                    with tf.GradientTape() as tape:\n",
    "                        tape.watch([tf.convert_to_tensor(w) for w in layer.trainable_weights])\n",
    "                        predictions = model(train_generator[0][0])\n",
    "                        loss = tf.keras.losses.categorical_crossentropy(train_generator[0][1], predictions)\n",
    "                    grads = tape.gradient(loss, layer.trainable_weights)\n",
    "                    for weight, grad in zip(layer.trainable_weights, grads):\n",
    "                        if isinstance(weight, tf.Variable):\n",
    "                            weight.assign_sub(grad * 0.01)  # Update step size\n",
    "\n",
    "        # Evaluate the model\n",
    "        loss, accuracy = model.evaluate(test_generator)\n",
    "        print(f'Test accuracy: {accuracy}')\n",
    "\n",
    "        model.save(model_path)\n",
    "\n",
    "    return model"
   ],
   "id": "1ec41897d59fefad"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "model = train_model(epochs=5)",
   "id": "24528144d0540046"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "class CardCounter:\n",
    "    high_cards = ('ten', 'jack', 'queen', 'king', 'ace')\n",
    "    low_cards = ('two', 'three', 'four', 'five', 'six')\n",
    "\n",
    "    def __init__(self, model, n_decks: int = 8):\n",
    "        self.model = model\n",
    "        self.n_decks = n_decks\n",
    "        self.total_cards = 52 * n_decks\n",
    "        self._count = 0\n",
    "        self._remaining_cards = {\n",
    "            'total': self.total_cards,\n",
    "            'high': int(round(self.total_cards * 5 / 13)),\n",
    "            'low': int(round(self.total_cards * 5 / 13)),\n",
    "            'neutral': int(round(self.total_cards * 3 / 13))\n",
    "        }\n",
    "\n",
    "        self.test_generator = ImageDataGenerator(rescale=1. / 255).flow_from_directory(\n",
    "            './data/test',\n",
    "            target_size=(224, 224),\n",
    "            batch_size=32,\n",
    "            class_mode='categorical'\n",
    "        )\n",
    "\n",
    "        self.card_counts = {label: 0 for label in self.test_generator.class_indices.keys()}\n",
    "\n",
    "    @property\n",
    "    def count(self):\n",
    "        return self._count\n",
    "\n",
    "    @count.setter\n",
    "    def count(self, count: int):\n",
    "        self._count = count\n",
    "\n",
    "    @property\n",
    "    def remaining_cards(self):\n",
    "        return self._remaining_cards\n",
    "\n",
    "    @remaining_cards.setter\n",
    "    def remaining_cards(self, remaining_cards: int):\n",
    "        self._remaining_cards = remaining_cards\n",
    "\n",
    "    def reset_deck(self):\n",
    "        self.total_cards = 52 * self.n_decks\n",
    "\n",
    "        self.remaining_cards = {\n",
    "            'total': self.total_cards,\n",
    "            'high': int(round(self.total_cards * 5 / 13)),\n",
    "            'low': int(round(self.total_cards * 5 / 13)),\n",
    "            'neutral': int(round(self.total_cards * 3 / 13))\n",
    "        }\n",
    "\n",
    "        self.count = 0\n",
    "        self.card_counts = {label: 0 for label in self.test_generator.class_indices.keys()}\n",
    "\n",
    "    def classify_card(self, image):\n",
    "        image = tf.image.resize(image, (224, 224))\n",
    "        image = tf.expand_dims(image, 0)  # Add batch dimension\n",
    "        predictions = self.model.predict(image)\n",
    "        class_index = tf.argmax(predictions[0]).numpy()\n",
    "        class_label = list(self.test_generator.class_indices.keys())[class_index]\n",
    "        return class_label\n",
    "\n",
    "    def count_cards(self, images):\n",
    "        high_cards = 0\n",
    "        low_cards = 0\n",
    "        neutral_cards = 0\n",
    "        card_labels = []\n",
    "        for image in images:\n",
    "            card_label = self.classify_card(image=image)\n",
    "            rank = card_label.split()[0]\n",
    "            suit = card_label.split()[-1]\n",
    "            card_labels.append((rank, suit))\n",
    "            self.card_counts[card_label] += 1\n",
    "\n",
    "            if card_label.split()[0] in self.high_cards:\n",
    "                self.count -= 1\n",
    "                high_cards += 1\n",
    "            elif card_label.split()[0] in self.low_cards:\n",
    "                self.count += 1\n",
    "                low_cards += 1\n",
    "            else:\n",
    "                neutral_cards += 1\n",
    "\n",
    "        # Calculate remaining cards\n",
    "        self.remaining_cards['total'] -= len(images)\n",
    "        self.remaining_cards['high'] -= high_cards\n",
    "        self.remaining_cards['low'] -= low_cards\n",
    "        self.remaining_cards['neutral'] -= neutral_cards\n",
    "\n",
    "        prob_high = self.remaining_cards['high'] / self.remaining_cards['total'] if self.remaining_cards['total'] > 0 else 0\n",
    "        prob_low = self.remaining_cards['low'] / self.remaining_cards['total'] if self.remaining_cards['total'] > 0 else 0\n",
    "        prob_neutral = self.remaining_cards['neutral'] / self.remaining_cards['total'] if self.remaining_cards['total'] > 0 else 0\n",
    "\n",
    "        return prob_high, prob_low, prob_neutral, card_labels"
   ],
   "id": "be6c5bf98940989d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "image_paths = [r'.\\data\\test\\ace of clubs\\1.jpg', r'.\\data\\test\\nine of clubs\\1.jpg', \n",
    "               r'.\\data\\test\\six of clubs\\1.jpg', r'.\\data\\test\\king of hearts\\1.jpg']\n",
    "\n",
    "images = [tf.io.read_file(image_path) for image_path in image_paths]\n",
    "images = [tf.image.decode_jpeg(image, channels=3) for image in images]"
   ],
   "id": "14a182526a45b397"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "card_counter = CardCounter(model=model)\n",
    "prob_high, prob_low, prob_neutral, card_labels = card_counter.count_cards(images=images)\n",
    "print(f'Predicted Cards: {card_labels}')\n",
    "print(f'Probability of next card being +1 count: {prob_low:.2f}')\n",
    "print(f'Probability of next card being -1 count: {prob_high:.2f}')\n",
    "print(f'Probability of next card being 0 count: {prob_neutral:.2f}')"
   ],
   "id": "11c4738d62d6261e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "class BlackjackGame:\n",
    "    def __init__(self, root, bankroll: int, model_path: str, cost: int = 100):\n",
    "        self.root = root\n",
    "        self.root.title(\"Blackjack Game\")\n",
    "\n",
    "        self.suits = ('hearts', 'diamonds', 'clubs', 'spades')\n",
    "        self.ranks = {\n",
    "            'two': 2,\n",
    "            'three': 3,\n",
    "            'four': 4,\n",
    "            'five': 5,\n",
    "            'six': 6,\n",
    "            'seven': 7,\n",
    "            'eight': 8,\n",
    "            'nine': 9,\n",
    "            'ten': 10,\n",
    "            'jack': 10,\n",
    "            'queen': 10,\n",
    "            'king': 10,\n",
    "            'ace': 11\n",
    "        }\n",
    "\n",
    "        # Load the trained model\n",
    "        self.model_path = model_path\n",
    "        self.model = self.load_model()\n",
    "\n",
    "        # Initialize the card counter\n",
    "        self.card_counter = CardCounter(model=self.model)\n",
    "        self.deck = self.create_deck()\n",
    "\n",
    "        # Initialize game variables\n",
    "        self.starting_bankroll = bankroll\n",
    "        self._bankroll = bankroll\n",
    "        self._cost = cost\n",
    "        self._blackjack_wins = 0\n",
    "        self._regular_wins = 0\n",
    "        self._losses = 0\n",
    "        self._draws = 0\n",
    "        self._hits = 0\n",
    "        self._splits = 0\n",
    "        self._stands = 0\n",
    "        self._hand_count = 0\n",
    "        self._active_hand = 0\n",
    "        self._dealer_hand = []\n",
    "        self._card_images = []\n",
    "        self._player_hands = [[]]\n",
    "        self._probabilities = {'High': [5 / 13], 'Low': [5 / 13], 'Neutral': [3 / 13]}\n",
    "        self._available_rewards = {'Blackjack': int(cost * 1.5), 'Regular': cost, 'Loss': -cost}\n",
    "        self.game_log = []\n",
    "\n",
    "        # Create a main container frame to hold player and dealer frames\n",
    "        self.main_container = tk.Frame(self.root)\n",
    "        self.main_container.pack(side=tk.LEFT, fill=tk.BOTH, expand=True)\n",
    "\n",
    "        self.player_label = tk.Label(self.main_container, text=\"Player's Hand\")\n",
    "        self.player_label.pack()\n",
    "\n",
    "        self.frames_container = tk.Frame(self.main_container)\n",
    "        self.frames_container.pack()\n",
    "\n",
    "        self._player_frames = [\n",
    "            tk.Frame(self.frames_container, padx=25) if i != 0 else tk.Frame(self.frames_container, padx=25,\n",
    "                                                                             bg='lightblue') for i in\n",
    "            range(4 * self.card_counter.n_decks)]\n",
    "        for frame in self._player_frames:\n",
    "            frame.pack(side=tk.LEFT)\n",
    "\n",
    "        self.dealer_label = tk.Label(self.main_container, text=\"Dealer's Hand\")\n",
    "        self.dealer_label.pack()\n",
    "        self.dealer_frame = tk.Frame(self.main_container)\n",
    "        self.dealer_frame.pack()\n",
    "\n",
    "        self.hit_button = tk.Button(self.main_container, text=\"Hit\", command=self.hit)\n",
    "        self.hit_button.pack(side=tk.LEFT)\n",
    "        self.stand_button = tk.Button(self.main_container, text=\"Stand\", command=self.stand)\n",
    "        self.stand_button.pack(side=tk.LEFT)\n",
    "        self.split_button = tk.Button(self.main_container, text=\"Split\", command=self.split)  # Add split button\n",
    "        self.split_button.pack(side=tk.LEFT)\n",
    "        self.reset_button = tk.Button(self.main_container, text=\"Reset\", command=self.reset_game)\n",
    "        self.reset_button.pack(side=tk.LEFT)\n",
    "\n",
    "        self.prob_label = tk.Label(self.main_container, text=f\"Probabilities - High: {self._probabilities['High'][0]}, Low: {self._probabilities['High'][0]}, Neutral: {self._probabilities['High'][0]}\")\n",
    "        self.prob_label.pack()\n",
    "\n",
    "        self.game_label = tk.Label(self.main_container, text=f'Game {self.regular_wins + self.blackjack_wins + self.losses + self.draws}: Blackjack Wins - {self.blackjack_wins}, Regular Wins - {self.regular_wins}, Losses - {self.losses}, Draws - {self.draws} -- Cards Left = {self.card_counter.remaining_cards[\"total\"]}')\n",
    "        self.game_label.pack()\n",
    "\n",
    "        self.wallet_label = tk.Label(self.main_container, text=f\"Bankroll: ${self.bankroll}\")\n",
    "        self.wallet_label.pack()\n",
    "\n",
    "        # Create the frame for the plots and logs\n",
    "        self.plot_frame = tk.Frame(self.root)\n",
    "        self.plot_frame.pack(side=tk.RIGHT, fill=tk.BOTH, expand=True)\n",
    "\n",
    "        # Plot frame should contain both the canvas and the log_frame side by side\n",
    "        self.fig, self.axs = plt.subplots(2, 2, figsize=(10, 8))\n",
    "        self.canvas = FigureCanvasTkAgg(self.fig, master=self.plot_frame)\n",
    "        self.canvas.get_tk_widget().pack(side=tk.TOP, fill=tk.BOTH, expand=True)\n",
    "\n",
    "        # Create a scrollable text widget for logs\n",
    "        self.log_frame = tk.Frame(self.plot_frame)\n",
    "        self.log_frame.pack(side=tk.BOTTOM, fill=tk.BOTH, expand=True)\n",
    "        self.log_text = tk.Text(self.log_frame, wrap=tk.WORD, state=tk.NORMAL)\n",
    "        self.log_text.pack(side=tk.LEFT, fill=tk.BOTH, expand=True)\n",
    "        self.log_scrollbar = ttk.Scrollbar(self.log_frame, command=self.log_text.yview)\n",
    "        self.log_scrollbar.pack(side=tk.RIGHT, fill=tk.Y)\n",
    "        self.log_text.config(yscrollcommand=self.log_scrollbar.set)\n",
    "\n",
    "        # Initialize data for plots\n",
    "        self._returns = []\n",
    "        self._average_returns = []\n",
    "\n",
    "        # Initialize the animation\n",
    "        self.ani = FuncAnimation(self.fig, self.update_plots, interval=1000)\n",
    "\n",
    "    @property\n",
    "    def bankroll(self):\n",
    "        return self._bankroll\n",
    "\n",
    "    @bankroll.setter\n",
    "    def bankroll(self, bankroll):\n",
    "        self._bankroll = bankroll\n",
    "\n",
    "    @property\n",
    "    def cost(self):\n",
    "        return self._cost\n",
    "\n",
    "    @cost.setter\n",
    "    def cost(self, cost):\n",
    "        self._cost = cost\n",
    "\n",
    "    @property\n",
    "    def blackjack_wins(self):\n",
    "        return self._blackjack_wins\n",
    "\n",
    "    @blackjack_wins.setter\n",
    "    def blackjack_wins(self, blackjack_wins):\n",
    "        self._blackjack_wins = blackjack_wins\n",
    "\n",
    "    @property\n",
    "    def regular_wins(self):\n",
    "        return self._regular_wins\n",
    "\n",
    "    @regular_wins.setter\n",
    "    def regular_wins(self, regular_wins):\n",
    "        self._regular_wins = regular_wins\n",
    "\n",
    "    @property\n",
    "    def losses(self):\n",
    "        return self._losses\n",
    "\n",
    "    @losses.setter\n",
    "    def losses(self, losses):\n",
    "        self._losses = losses\n",
    "\n",
    "    @property\n",
    "    def draws(self):\n",
    "        return self._draws\n",
    "\n",
    "    @draws.setter\n",
    "    def draws(self, draws):\n",
    "        self._draws = draws\n",
    "\n",
    "    @property\n",
    "    def hits(self):\n",
    "        return self._hits\n",
    "\n",
    "    @hits.setter\n",
    "    def hits(self, hits):\n",
    "        self._hits = hits\n",
    "\n",
    "    @property\n",
    "    def splits(self):\n",
    "        return self._splits\n",
    "\n",
    "    @splits.setter\n",
    "    def splits(self, splits):\n",
    "        self._splits = splits\n",
    "\n",
    "    @property\n",
    "    def stands(self):\n",
    "        return self._stands\n",
    "\n",
    "    @stands.setter\n",
    "    def stands(self, stands):\n",
    "        self._stands = stands\n",
    "\n",
    "    @property\n",
    "    def hand_count(self):\n",
    "        return self._hand_count\n",
    "\n",
    "    @hand_count.setter\n",
    "    def hand_count(self, hand_count):\n",
    "        self._hand_count = hand_count\n",
    "\n",
    "    @property\n",
    "    def active_hand(self):\n",
    "        return self._active_hand\n",
    "\n",
    "    @active_hand.setter\n",
    "    def active_hand(self, active_hand):\n",
    "        self._active_hand = active_hand\n",
    "\n",
    "    @property\n",
    "    def dealer_hand(self):\n",
    "        return self._dealer_hand\n",
    "\n",
    "    @dealer_hand.setter\n",
    "    def dealer_hand(self, dealer_hand):\n",
    "        self._dealer_hand = dealer_hand\n",
    "\n",
    "    @property\n",
    "    def card_images(self):\n",
    "        return self._card_images\n",
    "\n",
    "    @card_images.setter\n",
    "    def card_images(self, card_images):\n",
    "        self._card_images = card_images\n",
    "\n",
    "    @property\n",
    "    def player_hands(self):\n",
    "        return self._player_hands\n",
    "\n",
    "    @player_hands.setter\n",
    "    def player_hands(self, player_hands):\n",
    "        self._player_hands = player_hands\n",
    "\n",
    "    @property\n",
    "    def player_frames(self):\n",
    "        return self._player_frames\n",
    "\n",
    "    @player_frames.setter\n",
    "    def player_frames(self, player_frames):\n",
    "        self._player_frames = player_frames\n",
    "\n",
    "    @property\n",
    "    def probabilities(self):\n",
    "        return self._probabilities\n",
    "\n",
    "    @probabilities.setter\n",
    "    def probabilities(self, probabilities):\n",
    "        self._probabilities = probabilities\n",
    "\n",
    "    @property\n",
    "    def available_rewards(self):\n",
    "        return self._available_rewards\n",
    "\n",
    "    @available_rewards.setter\n",
    "    def available_rewards(self, available_rewards):\n",
    "        self._available_rewards = available_rewards\n",
    "\n",
    "    @property\n",
    "    def returns(self):\n",
    "        return self._returns\n",
    "\n",
    "    @returns.setter\n",
    "    def returns(self, returns):\n",
    "        self._returns = returns\n",
    "\n",
    "    @property\n",
    "    def average_returns(self):\n",
    "        return self._average_returns\n",
    "\n",
    "    @average_returns.setter\n",
    "    def average_returns(self, average_returns):\n",
    "        self._average_returns = average_returns\n",
    "\n",
    "    def log_prefix(self, idx: int):\n",
    "        return f'Hand {self.hand_count}: Active Hand {idx + 1} -'\n",
    "\n",
    "    def load_model(self, use_kan: bool = True):\n",
    "        input_shape = (224, 224, 3)\n",
    "        num_classes = 53  # 53 classes for 53 cards\n",
    "\n",
    "        model = KANCNN(input_shape, num_classes) if use_kan else Sequential([\n",
    "            Conv2D(32, (3, 3), activation='relu', input_shape=input_shape),\n",
    "            MaxPooling2D((2, 2)),\n",
    "            Conv2D(64, (3, 3), activation='relu'),\n",
    "            MaxPooling2D((2, 2)),\n",
    "            Conv2D(128, (3, 3), activation='relu'),\n",
    "            MaxPooling2D((2, 2)),\n",
    "            Flatten(),\n",
    "            Dense(512, activation='relu'),\n",
    "            Dropout(0.5),\n",
    "            Dense(num_classes, activation='softmax')\n",
    "        ])\n",
    "\n",
    "        model.compile(\n",
    "            optimizer='adam',\n",
    "            loss='categorical_crossentropy',\n",
    "            metrics=['accuracy']\n",
    "        )\n",
    "\n",
    "        model.load_weights(self.model_path)  # Load your trained model weights\n",
    "        return model\n",
    "\n",
    "    def create_deck(self):\n",
    "        deck = [(rank, suit) for rank in self.ranks.keys() for suit in self.suits for _ in\n",
    "                range(self.card_counter.n_decks)]\n",
    "        random.shuffle(deck)\n",
    "        return deck\n",
    "\n",
    "    def display_hand(self, card, is_dealer):\n",
    "        img_path = f'./data/test/{card[0]} of {card[1]}/1.jpg'\n",
    "\n",
    "        if not os.path.exists(img_path):\n",
    "            print(f\"Image path does not exist: {img_path}\")\n",
    "            return\n",
    "\n",
    "        images = [tf.image.decode_jpeg(tf.io.read_file(img_path), channels=3)]\n",
    "        prob_high, prob_low, prob_neutral, predicted_cards = self.card_counter.count_cards(images=images)\n",
    "        self.probabilities['High'].append(prob_high)\n",
    "        self.probabilities['Low'].append(prob_low)\n",
    "        self.probabilities['Neutral'].append(prob_neutral)\n",
    "\n",
    "        try:\n",
    "            img = Image.open(img_path)\n",
    "            img = img.resize((100, 150), Image.LANCZOS)\n",
    "            photo = ImageTk.PhotoImage(img)\n",
    "            self.card_images.append(photo)\n",
    "            frame = tk.Frame(self.dealer_frame if is_dealer else self.player_frames[self.active_hand])\n",
    "            frame.pack(side=tk.LEFT)\n",
    "            label = tk.Label(frame, image=photo)\n",
    "            label.image = photo\n",
    "            label.pack()\n",
    "            frame_text = f'{card[0]} of {card[1]}'\n",
    "            if is_dealer:\n",
    "                frame_text = f'Actual: {frame_text}\\nPredicted: {predicted_cards[0][0]} of {predicted_cards[0][1]}'\n",
    "\n",
    "            tk.Label(frame, text=frame_text).pack()\n",
    "        except Exception as e:\n",
    "            print(f\"Failed to load image {img_path}: {e}\")\n",
    "\n",
    "        self.update_probabilities_label()\n",
    "\n",
    "    def deal_card(self, hand: list, is_dealer: bool = False):\n",
    "        card = self.deck.pop()\n",
    "        self.card_counter.total_cards -= 1\n",
    "        if self.card_counter.total_cards == 0:\n",
    "            self.deck = self.create_deck()\n",
    "            self.card_counter.reset_deck()\n",
    "            self.probabilities = {'High': [5 / 13], 'Low': [5 / 13], 'Neutral': [3 / 13]}\n",
    "            self.card_images = []\n",
    "\n",
    "        hand.append(card)\n",
    "        self.display_hand(card=card, is_dealer=is_dealer)\n",
    "\n",
    "    def calculate_hand_value(self, hand):\n",
    "        value = 0\n",
    "        ace_count = 0\n",
    "        for card in hand:\n",
    "            rank = card[0]\n",
    "            value += self.ranks[rank]\n",
    "\n",
    "            if rank == 'ace':\n",
    "                ace_count += 1\n",
    "\n",
    "        while value > 21 and ace_count:\n",
    "            value -= 10\n",
    "            ace_count -= 1\n",
    "\n",
    "        return value\n",
    "\n",
    "    def update_probabilities_label(self):\n",
    "        self.prob_label.config(text=f'Probabilities - High: {self.probabilities[\"High\"][-1]:.2f}, Low: {self.probabilities[\"Low\"][-1]:.2f}, Neutral: {self.probabilities[\"Neutral\"][-1]:.2f}')\n",
    "\n",
    "    def update_game_label(self, rewards: int):\n",
    "        self.game_label.config(text=f'Game {self.regular_wins + self.blackjack_wins + self.losses + self.draws}: Blackjack Wins - {self.blackjack_wins}, Regular Wins - {self.regular_wins}, Losses - {self.losses}, Draws - {self.draws} -- Cards Left = {self.card_counter.remaining_cards[\"total\"]}')\n",
    "        self.bankroll += rewards\n",
    "        self.wallet_label.config(text=f\"Bankroll: ${self.bankroll}\")\n",
    "\n",
    "    def update_plots(self, *args):\n",
    "        win_data = {\n",
    "            \"regular_wins\": self.regular_wins,\n",
    "            \"blackjack_wins\": self.blackjack_wins,\n",
    "            \"losses\": self.losses,\n",
    "            \"draws\": self.draws\n",
    "        }\n",
    "\n",
    "        prob_data = {\n",
    "            \"high\": self.probabilities[\"High\"][-1],\n",
    "            \"low\": self.probabilities[\"Low\"][-1],\n",
    "            \"neutral\": self.probabilities[\"Neutral\"][-1]\n",
    "        }\n",
    "\n",
    "        action_data = {\n",
    "            \"hits\": self.hits,\n",
    "            \"stands\": self.stands,\n",
    "            \"splits\": self.splits\n",
    "        }\n",
    "\n",
    "        # Clear previous plots\n",
    "        for ax in self.axs.flat:\n",
    "            ax.clear()\n",
    "\n",
    "        # Plot 1: Wins, Losses, Draws\n",
    "        self.axs[0, 0].bar(win_data.keys(), win_data.values())\n",
    "        self.axs[0, 0].set_title(\"Wins, Losses, Draws\")\n",
    "        self.axs[0, 0].set_ylabel(\"Count\")\n",
    "        self.axs[0, 0].tick_params(axis='x', rotation=45)\n",
    "\n",
    "        # Plot 2: Probabilities\n",
    "        self.axs[0, 1].bar(prob_data.keys(), prob_data.values())\n",
    "        self.axs[0, 1].set_title(\"Probabilities\")\n",
    "        self.axs[0, 1].set_ylabel(\"Probability\")\n",
    "        self.axs[0, 1].tick_params(axis='x', rotation=45)\n",
    "\n",
    "        # Plot 3: Average Returns\n",
    "        if self.hand_count > 0:\n",
    "            self.axs[1, 0].plot(range(1, len(self.average_returns) + 1), self.average_returns)\n",
    "        self.axs[1, 0].set_title(\"Average Returns per Hand\")\n",
    "        self.axs[1, 0].set_ylabel(\"Average Return\")\n",
    "        self.axs[1, 0].set_xlabel(\"Number of Hands\")\n",
    "        self.axs[1, 0].tick_params(axis='x', rotation=45)\n",
    "\n",
    "        # Plot 4: Hits, Stands, Splits\n",
    "        self.axs[1, 1].bar(action_data.keys(), action_data.values())\n",
    "        self.axs[1, 1].set_title(\"Actions\")\n",
    "        self.axs[1, 1].set_ylabel(\"Count\")\n",
    "        self.axs[1, 1].tick_params(axis='x', rotation=45)\n",
    "\n",
    "        plt.subplots_adjust(left=0.1, right=0.9, top=0.9, bottom=0.2, wspace=0.4, hspace=0.8)\n",
    "\n",
    "        # Refresh the canvas\n",
    "        self.canvas.draw()\n",
    "\n",
    "    def log_message(self, message):\n",
    "        self.game_log.append(message)\n",
    "        self.log_text.config(state=tk.NORMAL)\n",
    "        self.log_text.insert(tk.END, message + \"\\n\")\n",
    "        self.log_text.config(state=tk.NORMAL)\n",
    "        self.log_text.yview(tk.END)\n",
    "\n",
    "    def start_game(self):\n",
    "        self.hand_count += 1\n",
    "        self.deal_card(self.player_hands[0])\n",
    "        self.deal_card(self.dealer_hand, is_dealer=True)\n",
    "        self.deal_card(self.player_hands[0])\n",
    "        self.deal_card(self.dealer_hand, is_dealer=True)\n",
    "\n",
    "        player_value = self.calculate_hand_value(self.player_hands[0])\n",
    "        dealer_value = self.calculate_hand_value(self.dealer_hand)\n",
    "        if player_value == 21:\n",
    "            reward = self.available_rewards[\"Blackjack\"]\n",
    "            self.blackjack_wins += 1\n",
    "            self.update_game_label(reward)\n",
    "            self.returns.append(reward)\n",
    "            self.average_returns.append(sum(self.returns) / self.hand_count)\n",
    "            message = f\"{self.log_prefix(0)} Blackjack! Player wins ${reward}!\"\n",
    "            self.log_message(message)\n",
    "            self.reset_hand()\n",
    "        elif dealer_value == 21:\n",
    "            reward = self.available_rewards[\"Loss\"]\n",
    "            self.losses += 1\n",
    "            self.update_game_label(reward)\n",
    "            self.returns.append(reward)\n",
    "            self.average_returns.append(sum(self.returns) / self.hand_count)\n",
    "            message = f\"{self.log_prefix(0)} Dealer Hit Blackjack. Player Loses ${-reward}\"\n",
    "            self.log_message(message)\n",
    "            self.reset_hand()\n",
    "        else:\n",
    "            self.update_game_label(0)\n",
    "\n",
    "        # Enable the split button if the player has two cards of the same rank\n",
    "        self.update_split_button_state()\n",
    "\n",
    "    def update_split_button_state(self):\n",
    "        can_split = any(len(hand) == 2 and hand[0][0] == hand[1][0] for hand in self.player_hands)\n",
    "        self.split_button.config(state=tk.NORMAL if can_split else tk.DISABLED)\n",
    "\n",
    "    def split(self):\n",
    "        # Check if the active hand can be split\n",
    "        active_hand = self.player_hands[self.active_hand]\n",
    "        if len(active_hand) == 2 and active_hand[0][0] == active_hand[1][0]:\n",
    "            self.splits += 1\n",
    "            new_hand = [self.player_hands[self.active_hand].pop()]\n",
    "            self.deal_card(new_hand)\n",
    "            self.deal_card(self.player_hands[self.active_hand])\n",
    "            self.player_hands.append(new_hand)\n",
    "\n",
    "        self.update_split_button_state()\n",
    "        for frame in self.player_frames[1:]:\n",
    "            frame.pack(side=tk.LEFT, padx=10)\n",
    "\n",
    "        self.update_hand_display()\n",
    "        self.update_game_label(0)\n",
    "        self.update_split_button_state()\n",
    "\n",
    "    def highlight_active_hand(self):\n",
    "        for idx, player_frame in enumerate(self.player_frames):\n",
    "            player_frame.config(bg='lightblue' if self.active_hand == idx else 'SystemButtonFace')\n",
    "\n",
    "        self.update_split_button_state()\n",
    "\n",
    "    def update_hand_display(self):\n",
    "        for player_frame in self.player_frames:\n",
    "            for widget in player_frame.winfo_children():\n",
    "                widget.destroy()\n",
    "\n",
    "        for idx, player_hand in enumerate(self.player_hands):\n",
    "            for card in player_hand:\n",
    "                img_path = f'./data/test/{card[0]} of {card[1]}/1.jpg'\n",
    "                if os.path.exists(img_path):\n",
    "                    try:\n",
    "                        img = Image.open(img_path)\n",
    "                        img = img.resize((100, 150), Image.LANCZOS)\n",
    "                        photo = ImageTk.PhotoImage(img)\n",
    "                        self.card_images.append(photo)\n",
    "                        frame = tk.Frame(self.player_frames[idx])\n",
    "                        frame.pack(side=tk.LEFT)\n",
    "                        label = tk.Label(frame, image=photo)\n",
    "                        label.image = photo\n",
    "                        label.pack()\n",
    "                        tk.Label(frame, text=f'{card[0]} of {card[1]}').pack()\n",
    "                    except Exception as e:\n",
    "                        print(f\"Failed to load image {img_path}: {e}\")\n",
    "\n",
    "        self.highlight_active_hand()\n",
    "\n",
    "    def hit(self):\n",
    "        self.deal_card(self.player_hands[self.active_hand])\n",
    "        self.hits += 1\n",
    "        player_value = self.calculate_hand_value(self.player_hands[self.active_hand])\n",
    "        if player_value >= 21:\n",
    "            self.stands -= 1\n",
    "            self.stand()\n",
    "\n",
    "        self.update_game_label(0)\n",
    "        self.update_split_button_state()\n",
    "\n",
    "    def compare_hands(self, player_value, dealer_value, hand_idx):\n",
    "        player_blackjack_win = player_value == 21\n",
    "        player_regular_win = (player_value < 21 and (dealer_value > 21 or player_value > dealer_value))\n",
    "        draw = player_value < 21 and player_value == dealer_value\n",
    "        dealer_wins = (dealer_value <= 21 and player_value < dealer_value) or player_value > 21\n",
    "\n",
    "        message = \"\"\n",
    "        if player_blackjack_win:\n",
    "            reward = self.available_rewards[\"Blackjack\"]\n",
    "            self.blackjack_wins += 1\n",
    "            self.update_game_label(reward)\n",
    "            self.returns.append(reward)\n",
    "            message = f\"{self.log_prefix(hand_idx)} Blackjack! Player wins ${reward}!\"\n",
    "        elif player_regular_win:\n",
    "            reward = self.available_rewards[\"Regular\"]\n",
    "            self.regular_wins += 1\n",
    "            self.update_game_label(reward)\n",
    "            self.returns.append(reward)\n",
    "\n",
    "            if player_value > dealer_value:\n",
    "                message += f\"{self.log_prefix(hand_idx)} Player wins ${reward}! Value: {player_value} > Dealer Value: {dealer_value}\"\n",
    "            elif dealer_value > 21:\n",
    "                message += f\"{self.log_prefix(hand_idx)} Player wins ${reward}! Dealer Busts with {dealer_value}\"\n",
    "\n",
    "        elif draw:\n",
    "            self.draws += 1\n",
    "            self.update_game_label(0)\n",
    "            self.returns.append(0)\n",
    "            message += f\"{self.log_prefix(hand_idx)} Draw! Value: {player_value} == Dealer Value: {dealer_value}\"\n",
    "        elif dealer_wins:\n",
    "            reward = self.available_rewards[\"Loss\"]\n",
    "            self.losses += 1\n",
    "            self.update_game_label(reward)\n",
    "            self.returns.append(reward)\n",
    "\n",
    "            if player_value < dealer_value:\n",
    "                message += f\"{self.log_prefix(hand_idx)} Player loses ${-reward}. Dealer Value: {dealer_value} > Value: {player_value}\"\n",
    "            elif player_value > 21:\n",
    "                message += f\"{self.log_prefix(hand_idx)} Player loses ${-reward}. Player Busts! {player_value}\"\n",
    "\n",
    "        self.log_message(message)\n",
    "\n",
    "    def stand(self):\n",
    "        self.stands += 1\n",
    "        if self.active_hand < len(self.player_hands) - 1:\n",
    "            self.active_hand += 1\n",
    "            self.highlight_active_hand()\n",
    "            if self.active_hand < len(self.player_hands):\n",
    "                return\n",
    "\n",
    "        # If no more hands to play, process the dealer's turn\n",
    "        while self.calculate_hand_value(self.dealer_hand) < 17:\n",
    "            self.deal_card(self.dealer_hand, is_dealer=True)\n",
    "\n",
    "        dealer_value = self.calculate_hand_value(self.dealer_hand)\n",
    "        player_values = [self.calculate_hand_value(hand) for hand in self.player_hands]\n",
    "\n",
    "        # Compare dealer's hand with player's hands\n",
    "        for idx, player_value in enumerate(player_values):\n",
    "            self.compare_hands(player_value, dealer_value, idx)\n",
    "\n",
    "        self.reset_hand()\n",
    "\n",
    "    def reset_hand(self):\n",
    "        if self.hand_count != 0:\n",
    "            self.average_returns.append(sum(self.returns) / self.hand_count)\n",
    "            messagebox.showinfo(\"Blackjack\", f'Hand {self.hand_count} completed')\n",
    "\n",
    "        # Clear and reinitialize player frames\n",
    "        for player_frame in self.player_frames:\n",
    "            for widget in player_frame.winfo_children():\n",
    "                widget.destroy()\n",
    "\n",
    "            player_frame.pack_forget()\n",
    "\n",
    "        self.player_frames = [tk.Frame(self.frames_container, padx=25) for _ in range(4 * self.card_counter.n_decks)]\n",
    "        for frame in self.player_frames:\n",
    "            frame.pack(side=tk.LEFT)\n",
    "\n",
    "        # Clear dealer frame\n",
    "        for widget in self.dealer_frame.winfo_children():\n",
    "            widget.destroy()\n",
    "\n",
    "        # Reinitialize hands and variables\n",
    "        self.player_hands = [[]]\n",
    "        self.dealer_hand = []\n",
    "        self.active_hand = 0\n",
    "\n",
    "        # Restart the game\n",
    "        self.start_game()\n",
    "        self.enable_buttons()\n",
    "\n",
    "    def disable_buttons(self):\n",
    "        self.hit_button.config(state=tk.DISABLED)\n",
    "        self.stand_button.config(state=tk.DISABLED)\n",
    "\n",
    "    def enable_buttons(self):\n",
    "        self.hit_button.config(state=tk.NORMAL)\n",
    "        self.stand_button.config(state=tk.NORMAL)\n",
    "\n",
    "    def reset_game(self):\n",
    "        message = f'Game Reset after {self.hand_count} hands\\nAverage return: ${sum(self.returns) / self.hand_count} / hand\\nTotal return: ${self.bankroll - self.starting_bankroll}, {self.blackjack_wins} Blackjacks, {self.regular_wins} Regular Wins, {self.losses} Losses, {self.draws} Draws\\n{self.hits} Hits, {self.splits} Splits, {self.stands} Stands'\n",
    "        self.log_message(message)\n",
    "        messagebox.showinfo(\"Blackjack\", message)\n",
    "        self.deck = self.create_deck()\n",
    "        self.card_counter.reset_deck()\n",
    "        self.bankroll = self.starting_bankroll\n",
    "        self.regular_wins = 0\n",
    "        self.blackjack_wins = 0\n",
    "        self.draws = 0\n",
    "        self.losses = 0\n",
    "        self.hits = 0\n",
    "        self.splits = 0\n",
    "        self.stands = 0\n",
    "        self.returns = []\n",
    "        self.average_returns = []\n",
    "        self.hand_count = 0\n",
    "        self.update_game_label(0)\n",
    "        self.card_images = []\n",
    "        self.probabilities = {'High': [5 / 13], 'Low': [5 / 13], 'Neutral': [3 / 13]}\n",
    "        self.reset_hand()"
   ],
   "id": "6cae855227a24e5f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Create the main window\n",
    "root = tk.Tk()\n",
    "game = BlackjackGame(root, 18000, './models/5_model.h5')\n",
    "game.start_game()\n",
    "root.mainloop()"
   ],
   "id": "94a254f261732096"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Now, use the prediction from the CNN model to feed the RL model information that will use slightly mislead it from the truth and the RL will have to learn to play blackjack by relying computer vision",
   "id": "24f9d35b80f6d948"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "class BlackjackEnvironment:\n",
    "    def __init__(self, model_path: str):\n",
    "        self.suits = ('hearts', 'diamonds', 'clubs', 'spades')\n",
    "        self.ranks = {\n",
    "            'two': 2,\n",
    "            'three': 3,\n",
    "            'four': 4,\n",
    "            'five': 5,\n",
    "            'six': 6,\n",
    "            'seven': 7,\n",
    "            'eight': 8,\n",
    "            'nine': 9,\n",
    "            'ten': 10,\n",
    "            'jack': 10,\n",
    "            'queen': 10,\n",
    "            'king': 10,\n",
    "            'ace': 11\n",
    "        }\n",
    "\n",
    "        # Load the trained model\n",
    "        self.model_path = model_path\n",
    "        self.model = self.load_model()\n",
    "\n",
    "        # Initialize the card counter\n",
    "        self.card_counter = CardCounter(model=self.model)\n",
    "        self.deck = self.create_deck()\n",
    "\n",
    "        self._blackjack_wins = 0\n",
    "        self._regular_wins = 0\n",
    "        self._losses = 0\n",
    "        self._draws = 0\n",
    "        self._hits = 0\n",
    "        self._splits = 0\n",
    "        self._stands = 0\n",
    "        self._hand_count = 0\n",
    "        self._active_hand = 0\n",
    "        self._dealer_hand = []\n",
    "        self._player_hands = [[]]\n",
    "        self._dealer_hand_real = []\n",
    "        self._player_hands_real = [[]]\n",
    "        self.reset_deck()\n",
    "\n",
    "    @property\n",
    "    def blackjack_wins(self):\n",
    "        return self._blackjack_wins\n",
    "\n",
    "    @blackjack_wins.setter\n",
    "    def blackjack_wins(self, blackjack_wins):\n",
    "        self._blackjack_wins = blackjack_wins\n",
    "\n",
    "    @property\n",
    "    def regular_wins(self):\n",
    "        return self._regular_wins\n",
    "\n",
    "    @regular_wins.setter\n",
    "    def regular_wins(self, regular_wins):\n",
    "        self._regular_wins = regular_wins\n",
    "\n",
    "    @property\n",
    "    def losses(self):\n",
    "        return self._losses\n",
    "\n",
    "    @losses.setter\n",
    "    def losses(self, losses):\n",
    "        self._losses = losses\n",
    "\n",
    "    @property\n",
    "    def draws(self):\n",
    "        return self._draws\n",
    "\n",
    "    @draws.setter\n",
    "    def draws(self, draws):\n",
    "        self._draws = draws\n",
    "\n",
    "    @property\n",
    "    def hits(self):\n",
    "        return self._hits\n",
    "\n",
    "    @hits.setter\n",
    "    def hits(self, hits):\n",
    "        self._hits = hits\n",
    "\n",
    "    @property\n",
    "    def splits(self):\n",
    "        return self._splits\n",
    "\n",
    "    @splits.setter\n",
    "    def splits(self, splits):\n",
    "        self._splits = splits\n",
    "\n",
    "    @property\n",
    "    def stands(self):\n",
    "        return self._stands\n",
    "\n",
    "    @stands.setter\n",
    "    def stands(self, stands):\n",
    "        self._stands = stands\n",
    "\n",
    "    @property\n",
    "    def hand_count(self):\n",
    "        return self._hand_count\n",
    "\n",
    "    @hand_count.setter\n",
    "    def hand_count(self, hand_count):\n",
    "        self._hand_count = hand_count\n",
    "\n",
    "    @property\n",
    "    def active_hand(self):\n",
    "        return self._active_hand\n",
    "\n",
    "    @active_hand.setter\n",
    "    def active_hand(self, active_hand):\n",
    "        self._active_hand = active_hand\n",
    "\n",
    "    @property\n",
    "    def dealer_hand(self):\n",
    "        return self._dealer_hand\n",
    "\n",
    "    @dealer_hand.setter\n",
    "    def dealer_hand(self, dealer_hand):\n",
    "        self._dealer_hand = dealer_hand\n",
    "\n",
    "    @property\n",
    "    def player_hands(self):\n",
    "        return self._player_hands\n",
    "\n",
    "    @player_hands.setter\n",
    "    def player_hands(self, player_hands):\n",
    "        self._player_hands = player_hands\n",
    "\n",
    "    @property\n",
    "    def dealer_hand_real(self):\n",
    "        return self._dealer_hand_real\n",
    "\n",
    "    @dealer_hand_real.setter\n",
    "    def dealer_hand_real(self, dealer_hand_real):\n",
    "        self._dealer_hand_real = dealer_hand_real\n",
    "\n",
    "    @property\n",
    "    def player_hands_real(self):\n",
    "        return self._player_hands_real\n",
    "\n",
    "    @player_hands_real.setter\n",
    "    def player_hands_real(self, player_hands_real):\n",
    "        self._player_hands_real = player_hands_real\n",
    "\n",
    "    def load_model(self, use_kan: bool = True):\n",
    "        input_shape = (224, 224, 3)\n",
    "        num_classes = 53  # 53 classes for 53 cards\n",
    "\n",
    "        model = KANCNN(input_shape, num_classes) if use_kan else Sequential([\n",
    "            Conv2D(32, (3, 3), activation='relu', input_shape=input_shape),\n",
    "            MaxPooling2D((2, 2)),\n",
    "            Conv2D(64, (3, 3), activation='relu'),\n",
    "            MaxPooling2D((2, 2)),\n",
    "            Conv2D(128, (3, 3), activation='relu'),\n",
    "            MaxPooling2D((2, 2)),\n",
    "            Flatten(),\n",
    "            Dense(512, activation='relu'),\n",
    "            Dropout(0.5),\n",
    "            Dense(num_classes, activation='softmax')\n",
    "        ])\n",
    "\n",
    "        model.compile(\n",
    "            optimizer='adam',\n",
    "            loss='categorical_crossentropy',\n",
    "            metrics=['accuracy']\n",
    "        )\n",
    "\n",
    "        model.load_weights(self.model_path)  # Load your trained model weights\n",
    "        return model\n",
    "\n",
    "    def create_deck(self):\n",
    "        deck = [(rank, suit) for rank in self.ranks.keys() for suit in self.suits for _ in\n",
    "                range(self.card_counter.n_decks)]\n",
    "        random.shuffle(deck)\n",
    "        return deck\n",
    "\n",
    "    def deal_card(self):\n",
    "        card = self.deck.pop()\n",
    "        self.card_counter.total_cards -= 1\n",
    "        if self.card_counter.total_cards == 0:\n",
    "            self.deck = self.create_deck()\n",
    "            self.card_counter.reset_deck()\n",
    "\n",
    "        img_path = f'./data/test/{card[0]} of {card[1]}/1.jpg'\n",
    "        images = [tf.image.decode_jpeg(tf.io.read_file(img_path), channels=3)]\n",
    "        prob_high, prob_low, prob_neutral, predicted_cards = self.card_counter.count_cards(images=images)\n",
    "        predicted_card = predicted_cards[0]\n",
    "\n",
    "        return card, predicted_card\n",
    "\n",
    "    def calculate_hand_value(self, hand):\n",
    "        value = 0\n",
    "        ace_count = 0\n",
    "        for card in hand:\n",
    "            rank = card[0]\n",
    "            value += self.ranks[rank]\n",
    "\n",
    "            if rank == 'ace':\n",
    "                ace_count += 1\n",
    "\n",
    "        while value > 21 and ace_count:\n",
    "            value -= 10\n",
    "            ace_count -= 1\n",
    "\n",
    "        return value\n",
    "\n",
    "    def reset(self):\n",
    "        self.player_hands = [[]]\n",
    "        self.player_hands_real = [[]]\n",
    "        self.dealer_hand_real = []\n",
    "        self.dealer_hand = []\n",
    "        self.active_hand = 0\n",
    "        \n",
    "        first_player_card, first_player_predicted_card = self.deal_card()\n",
    "        first_dealer_card, first_dealer_predicted_card = self.deal_card()\n",
    "        second_player_card, second_player_predicted_card = self.deal_card()\n",
    "        second_dealer_card, second_dealer_predicted_card = self.deal_card()\n",
    "        \n",
    "        self.player_hands[self.active_hand].append(first_player_predicted_card)\n",
    "        self.player_hands_real[self.active_hand].append(first_player_card)\n",
    "        self.dealer_hand.append(first_dealer_predicted_card)\n",
    "        self.dealer_hand_real.append(first_dealer_card)\n",
    "        self.player_hands[self.active_hand].append(second_player_predicted_card)\n",
    "        self.player_hands_real[self.active_hand].append(second_player_card)\n",
    "        self.dealer_hand.append(second_dealer_predicted_card)\n",
    "        self.dealer_hand_real.append(second_dealer_card)\n",
    "        \n",
    "        return self.get_state()\n",
    "\n",
    "    def reset_deck(self):\n",
    "        self.deck = self.create_deck()\n",
    "        self.card_counter.reset_deck()\n",
    "        self.probabilities = {'High': [5 / 13], 'Low': [5 / 13], 'Neutral': [3 / 13]}\n",
    "\n",
    "    def get_state(self):\n",
    "        player_hand_value = self.calculate_hand_value(self.player_hands[self.active_hand])\n",
    "        dealer_upcard = self.ranks[self.dealer_hand[0][0]]\n",
    "        usable_a = self.usable_ace(self.player_hands[self.active_hand])\n",
    "        can_split = len(self.player_hands[self.active_hand]) == 2 and self.player_hands[self.active_hand][0][0] == self.player_hands[self.active_hand][1][0]\n",
    "        return (player_hand_value, dealer_upcard, usable_a, len(self.player_hands), can_split)\n",
    "\n",
    "    def usable_ace(self, hand):\n",
    "        return any(card[0] == 'ace' for card in hand) and self.calculate_hand_value(hand) + 10 <= 21\n",
    "\n",
    "    def step(self, action):\n",
    "        if action == 'hit':\n",
    "            self.hits += 1\n",
    "            card, predicted_card = self.deal_card()\n",
    "            self.player_hands_real[self.active_hand].append(card)\n",
    "            self.player_hands[self.active_hand].append(predicted_card)\n",
    "            player_value = self.calculate_hand_value(self.player_hands_real[self.active_hand])\n",
    "            if player_value > 21:\n",
    "                self.losses += 1\n",
    "                reward = -1\n",
    "                done = True\n",
    "                return self.get_state(), reward, done\n",
    "            if player_value == 21:\n",
    "                self.blackjack_wins += 1\n",
    "                reward = 1.5\n",
    "                done = True\n",
    "                return self.get_state(), reward, done\n",
    "\n",
    "        elif action == 'stand':\n",
    "            self.stands += 1\n",
    "            if self.active_hand < len(self.player_hands) - 1:\n",
    "                self.active_hand += 1\n",
    "                reward = 0\n",
    "                done = False\n",
    "                return self.get_state(), reward, done\n",
    "\n",
    "            while self.calculate_hand_value(self.dealer_hand_real) < 17:\n",
    "                card, predicted_card = self.deal_card()\n",
    "                self.dealer_hand.append(predicted_card)\n",
    "                self.dealer_hand_real.append(card)\n",
    "\n",
    "            dealer_value = self.calculate_hand_value(self.dealer_hand_real)\n",
    "            rewards = 0\n",
    "            for hand in self.player_hands_real:\n",
    "                player_value = self.calculate_hand_value(hand)\n",
    "                if player_value == 21:\n",
    "                    rewards += 1.5\n",
    "                    self.blackjack_wins += 1\n",
    "                elif player_value < dealer_value <= 21:\n",
    "                    rewards -= 1\n",
    "                    self.losses += 1\n",
    "                elif dealer_value > 21 or player_value > dealer_value:\n",
    "                    rewards += 1\n",
    "                    self.regular_wins += 1\n",
    "                elif player_value == dealer_value and player_value < 21:\n",
    "                    self.draws += 1\n",
    "\n",
    "            done = True\n",
    "            return self.get_state(), rewards, done\n",
    "\n",
    "        elif action == 'split' and len(self.player_hands_real[self.active_hand]) == 2 and self.player_hands_real[self.active_hand][0][0] == self.player_hands_real[self.active_hand][1][0]:\n",
    "            self.splits += 1\n",
    "            first_card, first_predicted_card = self.deal_card()\n",
    "            second_card, second_predicted_card = self.deal_card()\n",
    "            new_hand = [self.player_hands[self.active_hand].pop()]\n",
    "            new_real_hand = [self.player_hands_real[self.active_hand].pop()]\n",
    "\n",
    "            self.player_hands_real[self.active_hand].append(first_card)\n",
    "            self.player_hands[self.active_hand].append(first_predicted_card)\n",
    "            new_hand.append(second_predicted_card)\n",
    "            new_real_hand.append(second_card)\n",
    "\n",
    "            self.player_hands_real.append(new_real_hand)\n",
    "            self.player_hands.append(new_hand)\n",
    "            reward = 0\n",
    "            done = False\n",
    "            return self.get_state(), reward, done\n",
    "\n",
    "        return self.get_state(), 0, False\n",
    "\n",
    "\n",
    "class QLearningAgent:\n",
    "    def __init__(self, action_space, alpha=0.1, gamma=0.99, epsilon=0.1):\n",
    "        self.alpha = alpha\n",
    "        self.gamma = gamma\n",
    "        self.epsilon = epsilon\n",
    "        self.q_table = defaultdict(lambda: np.zeros(len(action_space)))\n",
    "        self.actions = action_space\n",
    "        self.rewards = []\n",
    "        self.action_counts = defaultdict(int)\n",
    "\n",
    "    def choose_action(self, state):\n",
    "        if np.random.random() < self.epsilon:\n",
    "            available_actions = self.actions if state[4] else [a for a in self.actions if a != 'split']\n",
    "            action = np.random.choice(available_actions)\n",
    "        else:\n",
    "            q_values = self.q_table[state]\n",
    "            if not state[4]:\n",
    "                self.q_table[state][self.actions.index('split')] = -float('inf')\n",
    "\n",
    "            action = self.actions[np.argmax(q_values)]\n",
    "\n",
    "        self.action_counts[action] += 1\n",
    "        return action\n",
    "\n",
    "    def update_q_value(self, state, action, reward, next_state):\n",
    "        if not state[4]:\n",
    "            self.q_table[state][self.actions.index('split')] = -float('inf')\n",
    "\n",
    "        if not next_state[4]:\n",
    "            self.q_table[next_state][self.actions.index('split')] = -float('inf')\n",
    "\n",
    "        action_idx = self.actions.index(action)\n",
    "        best_next_action = np.argmax(self.q_table[next_state])\n",
    "        td_target = reward + self.gamma * self.q_table[next_state][best_next_action]\n",
    "        self.q_table[state][action_idx] += self.alpha * (td_target - self.q_table[state][action_idx])\n",
    "\n",
    "    def train(self, environment, episodes):\n",
    "        for episode in range(episodes):\n",
    "            state = environment.reset()\n",
    "            total_reward = 0\n",
    "            done = False\n",
    "            while not done:\n",
    "                action = self.choose_action(state)\n",
    "                next_state, reward, done = environment.step(action)\n",
    "                self.update_q_value(state, action, reward, next_state)\n",
    "                state = next_state\n",
    "                total_reward += reward\n",
    "\n",
    "            self.rewards.append(total_reward)\n",
    "\n",
    "        return self.rewards\n",
    "\n",
    "    def save_model(self, filename):\n",
    "        with open(filename, 'wb') as f:\n",
    "            pickle.dump(self.q_table, f)\n",
    "\n",
    "    def load_model(self, filename):\n",
    "        with open(filename, 'rb') as f:\n",
    "            self.q_table = pickle.load(f)\n",
    "\n",
    "\n",
    "class BlackjackRL:\n",
    "    def __init__(self, root, agent, environment, train_episodes, test_episodes, cnn_model_path):\n",
    "        self.root = root\n",
    "        self.root.title(\"Blackjack RL Agent\")\n",
    "        self.agent = agent\n",
    "        self.environment = environment\n",
    "        self.train_episodes = train_episodes\n",
    "        self.test_episodes = test_episodes\n",
    "        self._probabilities = {'High': [5 / 13], 'Low': [5 / 13], 'Neutral': [3 / 13]}\n",
    "        self.card_images = []\n",
    "        self.game_log = []\n",
    "        self.training = False\n",
    "\n",
    "        # Get screen width and height\n",
    "        screen_width = self.root.winfo_screenwidth()\n",
    "        screen_height = self.root.winfo_screenheight()\n",
    "\n",
    "        # Set window size as a percentage of screen size\n",
    "        window_width = int(screen_width * 0.95)\n",
    "        window_height = int(screen_height * 0.9)\n",
    "        self.root.geometry(f\"{window_width}x{window_height}\")\n",
    "\n",
    "        # Calculate padding as percentages of screen dimensions\n",
    "        self.padx = int(screen_width * 0.01)\n",
    "        self.pady = int(screen_height * 0.01)\n",
    "        self.num_columns = 4\n",
    "\n",
    "        # Load the trained model\n",
    "        self.cnn_model_path = cnn_model_path\n",
    "        self.cnn_model = self.load_cnn_model()\n",
    "        self.card_counter = CardCounter(model=self.cnn_model)\n",
    "\n",
    "        # Create frames\n",
    "        self.game_frame = tk.Frame(self.root)\n",
    "        self.game_frame.pack(side=tk.LEFT, padx=self.padx, pady=self.pady, expand=True, fill='both')\n",
    "        self.stats_frame = tk.Frame(self.root)\n",
    "        self.stats_frame.pack(side=tk.RIGHT, padx=self.padx, pady=self.pady, expand=True, fill='both')\n",
    "\n",
    "        # Create game widgets\n",
    "        self.player_label = tk.Label(self.game_frame, text=\"Player's Hand\")\n",
    "        self.player_label.grid(row=0, column=0, columnspan=self.num_columns)\n",
    "        self.player_frames = [tk.Frame(self.game_frame) for _ in range(4)]\n",
    "        for idx, frame in enumerate(self.player_frames):\n",
    "            frame.grid(row=1, column=idx, padx=self.padx, pady=self.pady, sticky='nsew')\n",
    "\n",
    "        self.dealer_label = tk.Label(self.game_frame, text=\"Dealer's Hand\")\n",
    "        self.dealer_label.grid(row=2, column=0, columnspan=self.num_columns, pady=(self.pady * 2, 0))\n",
    "        self.dealer_frame = tk.Frame(self.game_frame)\n",
    "        self.dealer_frame.grid(row=3, column=0, columnspan=self.num_columns, padx=self.padx, pady=self.pady, sticky='nsew')\n",
    "\n",
    "        self.start_button = tk.Button(self.game_frame, text=\"Start Training\", command=self.start_training)\n",
    "        self.start_button.grid(row=4, column=0, padx=self.padx, pady=self.pady)\n",
    "        self.stop_button = tk.Button(self.game_frame, text=\"Stop Training\", command=self.stop_training, state=tk.DISABLED)\n",
    "        self.stop_button.grid(row=4, column=1, padx=self.padx, pady=self.pady)\n",
    "        self.save_button = tk.Button(self.game_frame, text=\"Save Model\", command=self.save_rl_model)\n",
    "        self.save_button.grid(row=5, column=0, padx=self.padx, pady=self.pady)\n",
    "        self.load_button = tk.Button(self.game_frame, text=\"Load Model\", command=self.load_rl_model)\n",
    "        self.load_button.grid(row=5, column=1, padx=self.padx, pady=self.pady)\n",
    "\n",
    "        self.test_button = tk.Button(self.game_frame, text=\"Test Agent\", command=lambda: self.test_agent(games=test_episodes), state=tk.DISABLED)\n",
    "        self.test_button.grid(row=6, column=0, columnspan=self.num_columns, pady=self.pady)\n",
    "\n",
    "        # Create stats widgets with adjusted sizes\n",
    "        fig_width = window_width / 3 / 100\n",
    "        fig_height = window_height / 3 / 100\n",
    "\n",
    "        # Create stats widgets\n",
    "        self.cumulative_rewards_fig, self.cumulative_rewards_ax = plt.subplots(figsize=(fig_width, fig_height))\n",
    "        self.cumulative_rewards_canvas = FigureCanvasTkAgg(self.cumulative_rewards_fig, master=self.stats_frame)\n",
    "        self.cumulative_rewards_canvas.get_tk_widget().grid(row=0, column=0)\n",
    "\n",
    "        self.average_rewards_fig, self.average_rewards_ax = plt.subplots(figsize=(fig_width, fig_height))\n",
    "        self.average_rewards_canvas = FigureCanvasTkAgg(self.average_rewards_fig, master=self.stats_frame)\n",
    "        self.average_rewards_canvas.get_tk_widget().grid(row=0, column=1)\n",
    "\n",
    "        self.win_loss_fig, self.win_loss_ax = plt.subplots(figsize=(fig_width, fig_height))\n",
    "        self.win_loss_canvas = FigureCanvasTkAgg(self.win_loss_fig, master=self.stats_frame)\n",
    "        self.win_loss_canvas.get_tk_widget().grid(row=1, column=0)\n",
    "\n",
    "        self.prob_fig, self.prob_ax = plt.subplots(figsize=(fig_width, fig_height))\n",
    "        self.prob_canvas = FigureCanvasTkAgg(self.prob_fig, master=self.stats_frame)\n",
    "        self.prob_canvas.get_tk_widget().grid(row=1, column=1)\n",
    "\n",
    "        self.q_values_fig, self.q_values_ax = plt.subplots(figsize=(fig_width, fig_height))\n",
    "        self.q_values_canvas = FigureCanvasTkAgg(self.q_values_fig, master=self.stats_frame)\n",
    "        self.q_values_canvas.get_tk_widget().grid(row=2, column=0)\n",
    "\n",
    "        self.action_counts_fig, self.action_counts_ax = plt.subplots(figsize=(fig_width, fig_height))\n",
    "        self.action_counts_canvas = FigureCanvasTkAgg(self.action_counts_fig, master=self.stats_frame)\n",
    "        self.action_counts_canvas.get_tk_widget().grid(row=2, column=1)\n",
    "\n",
    "        # Create a scrollable text widget for logs\n",
    "        self.log_frame = tk.Frame(self.stats_frame)\n",
    "        self.log_frame.grid(row=3, column=0, columnspan=2, sticky='nsew')\n",
    "        self.log_text = tk.Text(self.log_frame, wrap=tk.WORD, state=tk.NORMAL, width=80, height=10)\n",
    "        self.log_text.pack(side=tk.LEFT, fill=tk.BOTH, expand=True)\n",
    "        self.log_scrollbar = ttk.Scrollbar(self.log_frame, command=self.log_text.yview)\n",
    "        self.log_scrollbar.pack(side=tk.RIGHT, fill=tk.Y)\n",
    "        self.log_text.config(yscrollcommand=self.log_scrollbar.set)\n",
    "\n",
    "        self.episode_count = 0\n",
    "\n",
    "    @property\n",
    "    def probabilities(self):\n",
    "        return self._probabilities\n",
    "\n",
    "    @probabilities.setter\n",
    "    def probabilities(self, probabilities):\n",
    "        self._probabilities = probabilities\n",
    "\n",
    "    def load_cnn_model(self, use_kan: bool = True):\n",
    "        input_shape = (224, 224, 3)\n",
    "        num_classes = 53  # 53 classes for 53 cards\n",
    "\n",
    "        model = KANCNN(input_shape, num_classes) if use_kan else Sequential([\n",
    "            Conv2D(32, (3, 3), activation='relu', input_shape=input_shape),\n",
    "            MaxPooling2D((2, 2)),\n",
    "            Conv2D(64, (3, 3), activation='relu'),\n",
    "            MaxPooling2D((2, 2)),\n",
    "            Conv2D(128, (3, 3), activation='relu'),\n",
    "            MaxPooling2D((2, 2)),\n",
    "            Flatten(),\n",
    "            Dense(512, activation='relu'),\n",
    "            Dropout(0.5),\n",
    "            Dense(num_classes, activation='softmax')\n",
    "        ])\n",
    "\n",
    "        model.compile(\n",
    "            optimizer='adam',\n",
    "            loss='categorical_crossentropy',\n",
    "            metrics=['accuracy']\n",
    "        )\n",
    "\n",
    "        model.load_weights(self.cnn_model_path)  # Load your trained model weights\n",
    "        return model\n",
    "\n",
    "    def save_rl_model(self):\n",
    "        file_path = filedialog.asksaveasfilename(defaultextension=\".h5\", filetypes=[(\"H5 files\", \"*.h5\"), (\"PKL files\", \"*.pkl\"), (\"All files\", \"*.*\")])\n",
    "        if file_path:\n",
    "            self.agent.save_model(file_path)\n",
    "            print(f\"Model saved to: {file_path}\")\n",
    "\n",
    "    def load_rl_model(self):\n",
    "        file_path = filedialog.askopenfilename(filetypes=[(\"H5 files\", \"*.h5\"), (\"PKL files\", \"*.pkl\"), (\"All files\", \"*.*\")])\n",
    "        if file_path:\n",
    "            self.agent.load_model(file_path)\n",
    "            print(f\"Model loaded from: {file_path}\")\n",
    "\n",
    "    def display_hand(self, hand, frame, is_dealer=True):\n",
    "        for widget in frame.winfo_children():\n",
    "            widget.destroy()\n",
    "\n",
    "        for i, card in enumerate(hand):\n",
    "            img_path = f'./data/test/{card[0]} of {card[1]}/1.jpg'\n",
    "\n",
    "            # Debugging: Check if the image path exists\n",
    "            if not os.path.exists(img_path):\n",
    "                print(f\"Image path does not exist: {img_path}\")\n",
    "                continue\n",
    "\n",
    "            images = [tf.image.decode_jpeg(tf.io.read_file(img_path), channels=3)]\n",
    "            prob_high, prob_low, prob_neutral, predicted_cards = self.card_counter.count_cards(images=images)\n",
    "            predicted_card = predicted_cards[0]\n",
    "            predicted_img_path = f'./data/test/{predicted_card[0]} of {predicted_card[1]}/1.jpg'\n",
    "\n",
    "            if not os.path.exists(predicted_img_path):\n",
    "                print(f\"Image path does not exist: {predicted_img_path}\")\n",
    "                return\n",
    "\n",
    "            try:\n",
    "                img = Image.open(img_path)\n",
    "                img = img.resize((100, 150), Image.LANCZOS)\n",
    "                photo = ImageTk.PhotoImage(img)\n",
    "                self.card_images.append(photo)  # Keep a reference to the image\n",
    "                label = tk.Label(frame, image=photo)\n",
    "                label.image = photo  # Ensure reference is kept by the label\n",
    "                label.grid(row=0, column=i)\n",
    "                frame_text = f'{card[0]} of {card[1]}'\n",
    "                if is_dealer:\n",
    "                    frame_text = f'Actual: {frame_text}\\nPredicted: {predicted_card[0]} of {predicted_card[1]}'\n",
    "\n",
    "                tk.Label(frame, text=frame_text).grid(row=1, column=i)\n",
    "            except Exception as e:\n",
    "                print(f\"Failed to load image {img_path}: {e}\")\n",
    "\n",
    "        return hand\n",
    "\n",
    "    def update_stats(self):\n",
    "        # Update cumulative rewards plot\n",
    "        cumulative_rewards = np.cumsum(self.agent.rewards)\n",
    "        self.cumulative_rewards_ax.clear()\n",
    "        self.cumulative_rewards_ax.plot(cumulative_rewards, label='Cumulative Reward')\n",
    "        self.cumulative_rewards_ax.set_xlabel('Episode')\n",
    "        self.cumulative_rewards_ax.set_ylabel('Cumulative Reward')\n",
    "        self.cumulative_rewards_ax.set_title('Cumulative Rewards Over Time')\n",
    "        self.cumulative_rewards_ax.legend()\n",
    "        self.cumulative_rewards_canvas.draw()\n",
    "\n",
    "        # Update average rewards plot\n",
    "        average_rewards = cumulative_rewards / (np.arange(len(self.agent.rewards)) + 1)\n",
    "        self.average_rewards_ax.clear()\n",
    "        self.average_rewards_ax.plot(average_rewards, label='Average Reward per Episode')\n",
    "        self.average_rewards_ax.set_xlabel('Episode')\n",
    "        self.average_rewards_ax.set_ylabel('Average Reward')\n",
    "        self.average_rewards_ax.set_title('Average Rewards Over Time')\n",
    "        self.average_rewards_ax.legend()\n",
    "        self.average_rewards_canvas.draw()\n",
    "\n",
    "        # Update win/loss plot\n",
    "        win_data = {\n",
    "            \"Regular Wins\": self.environment.regular_wins,\n",
    "            \"Blackjack Wins\": self.environment.blackjack_wins,\n",
    "            \"Losses\": self.environment.losses,\n",
    "            \"Draws\": self.environment.draws\n",
    "        }\n",
    "        self.win_loss_ax.clear()\n",
    "        self.win_loss_ax.bar(win_data.keys(), win_data.values())\n",
    "        self.win_loss_ax.set_title(\"Wins, Losses, Draws\")\n",
    "        self.win_loss_ax.set_ylabel(\"Count\")\n",
    "        self.win_loss_canvas.draw()\n",
    "\n",
    "        # Update probability plot\n",
    "        prob_data = {\n",
    "            \"High\": self.probabilities[\"High\"][-1],\n",
    "            \"Low\": self.probabilities[\"Low\"][-1],\n",
    "            \"Neutral\": self.probabilities[\"Neutral\"][-1]\n",
    "        }\n",
    "        self.prob_ax.clear()\n",
    "        self.prob_ax.bar(prob_data.keys(), prob_data.values())\n",
    "        self.prob_ax.set_title(\"Card Probabilities\")\n",
    "        self.prob_ax.set_ylabel(\"Count\")\n",
    "        self.prob_canvas.draw()\n",
    "\n",
    "        # Update Q-values plot\n",
    "        state = self.environment.get_state()\n",
    "        q_values = self.agent.q_table[state]\n",
    "        if not state[4]:\n",
    "            q_values[self.agent.actions.index('split')] = 0\n",
    "\n",
    "        self.q_values_ax.clear()\n",
    "        self.q_values_ax.bar(self.agent.actions, q_values)\n",
    "        self.q_values_ax.set_xlabel('Actions')\n",
    "        self.q_values_ax.set_ylabel('Q-values')\n",
    "        self.q_values_ax.set_title('Q-values for Current State')\n",
    "        self.q_values_canvas.draw()\n",
    "\n",
    "        # Update action counts plot\n",
    "        actions = list(self.agent.action_counts.keys())\n",
    "        counts = list(self.agent.action_counts.values())\n",
    "        self.action_counts_ax.clear()\n",
    "        self.action_counts_ax.bar(actions, counts)\n",
    "        self.action_counts_ax.set_xlabel('Actions')\n",
    "        self.action_counts_ax.set_ylabel('Counts')\n",
    "        self.action_counts_ax.set_title('Action Selection Frequency')\n",
    "        self.action_counts_canvas.draw()\n",
    "\n",
    "    def log_message(self, message):\n",
    "        self.game_log.append(message)\n",
    "        self.log_text.config(state=tk.NORMAL)\n",
    "        self.log_text.insert(tk.END, message + \"\\n\")\n",
    "        self.log_text.config(state=tk.NORMAL)\n",
    "        self.log_text.yview(tk.END)\n",
    "\n",
    "    def start_training(self):\n",
    "        self.training = True\n",
    "        self.start_button.config(state=tk.DISABLED)\n",
    "        self.stop_button.config(state=tk.NORMAL)\n",
    "        self.test_button.config(state=tk.DISABLED)\n",
    "        self.train_agent()\n",
    "\n",
    "    def stop_training(self):\n",
    "        self.training = False\n",
    "        self.start_button.config(state=tk.NORMAL)\n",
    "        self.stop_button.config(state=tk.DISABLED)\n",
    "        self.test_button.config(state=tk.NORMAL)\n",
    "\n",
    "    def reset_game(self):\n",
    "        self.environment.reset()\n",
    "        for frame in self.player_frames:\n",
    "            for widget in frame.winfo_children():\n",
    "                widget.destroy()\n",
    "\n",
    "        for widget in self.dealer_frame.winfo_children():\n",
    "            widget.destroy()\n",
    "\n",
    "        self.update_stats()\n",
    "\n",
    "    def train_agent(self):\n",
    "        if not self.training:\n",
    "            return\n",
    "\n",
    "        self.reset_game()\n",
    "        state = self.environment.reset()\n",
    "        done = False\n",
    "        while not done:\n",
    "            self.root.update_idletasks()\n",
    "            self.root.update()\n",
    "            action = self.agent.choose_action(state)\n",
    "            next_state, reward, done = self.environment.step(action)\n",
    "            self.agent.update_q_value(state, action, reward, next_state)\n",
    "            self.agent.rewards.append(reward)\n",
    "            state = next_state\n",
    "            self.update_hand_display()\n",
    "            if done:\n",
    "                self.episode_count += 1\n",
    "                self.update_stats()\n",
    "                self.log_message(f\"Episode {self.episode_count}: Reward {reward}\")\n",
    "                self.root.after(1000, self.train_agent)\n",
    "                break\n",
    "            self.root.after(1000, lambda: None)  # Add delay for visualization\n",
    "\n",
    "    def update_hand_display(self):\n",
    "        for idx, hand in enumerate(self.environment.player_hands_real):\n",
    "            self.display_hand(hand, self.player_frames[idx])\n",
    "\n",
    "        self.display_hand(self.environment.dealer_hand_real, self.dealer_frame, is_dealer=True)\n",
    "\n",
    "    def test_agent(self, games=100):\n",
    "        wins, losses, draws = 0, 0, 0\n",
    "        for _ in range(games):\n",
    "            state = self.environment.reset()\n",
    "            done = False\n",
    "            while not done:\n",
    "                action = self.agent.choose_action(state)\n",
    "                next_state, reward, done = self.environment.step(action)\n",
    "                state = next_state\n",
    "                if done:\n",
    "                    if reward == 1:\n",
    "                        wins += 1\n",
    "                    elif reward == -1:\n",
    "                        losses += 1\n",
    "                    else:\n",
    "                        draws += 1\n",
    "\n",
    "        messagebox.showinfo(\"Test Results\", f\"Results over {games} games:\\nWins: {wins}\\nLosses: {losses}\\nDraws: {draws}\")\n",
    "\n",
    "    def start(self):\n",
    "        self.root.mainloop()"
   ],
   "id": "af49815b7b7ca366"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Create a Q-Learning Reinforcement Learning model to learn to play blackjack\n",
    "epochs = 5\n",
    "model_path = f'./models/{epochs}_model.h5'\n",
    "env = BlackjackEnvironment(model_path)\n",
    "actions = ['hit', 'stand', 'split']\n",
    "agent = QLearningAgent(action_space=actions)\n",
    "root = tk.Tk()\n",
    "app = BlackjackRL(\n",
    "    root=root,\n",
    "    agent=agent,\n",
    "    environment=env,\n",
    "    train_episodes=1000,\n",
    "    test_episodes=100,\n",
    "    cnn_model_path=model_path\n",
    ")\n",
    "\n",
    "app.start()"
   ],
   "id": "68de8fd8db17b80"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Now to use Deep Q Learning (DQN) in order to get the reinforcement learning model to take the probabilities of the card counter into account",
   "id": "a141f36ff030c73e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "class DQN(nn.Module):\n",
    "    def __init__(self, state_size, action_size):\n",
    "        super(DQN, self).__init__()\n",
    "        self.fc1 = nn.Linear(state_size, 64)\n",
    "        self.fc2 = nn.Linear(64, 64)\n",
    "        self.fc3 = nn.Linear(64, action_size)\n",
    "\n",
    "    def forward(self, state):\n",
    "        x = torch.relu(self.fc1(state))\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class DQNAgent:\n",
    "    def __init__(self, state_size, action_space, gamma=0.99, epsilon=1.0, epsilon_min=0.01, epsilon_decay=0.995,\n",
    "                 learning_rate=0.001, batch_size=32):\n",
    "        self.state_size = state_size\n",
    "        self.action_size = len(action_space)\n",
    "        self.action_space = action_space\n",
    "        self.memory = deque(maxlen=2000)\n",
    "        self.gamma = gamma\n",
    "        self.epsilon = epsilon\n",
    "        self.epsilon_min = epsilon_min\n",
    "        self.epsilon_decay = epsilon_decay\n",
    "        self.learning_rate = learning_rate\n",
    "        self.batch_size = batch_size\n",
    "        self.model = DQN(state_size, self.action_size)\n",
    "        self.optimizer = optim.Adam(self.model.parameters(), lr=self.learning_rate)\n",
    "        self.criterion = nn.MSELoss()\n",
    "        self.rewards = []\n",
    "        self.action_counts = defaultdict(int)\n",
    "\n",
    "    def remember(self, state, action, reward, next_state, done):\n",
    "        action_idx = self.action_space.index(action)\n",
    "        self.memory.append((state, action_idx, reward, next_state, done))\n",
    "\n",
    "    def act(self, state):\n",
    "        if np.random.rand() <= self.epsilon:\n",
    "            available_actions = self.action_space if state[-1] else [a for a in self.action_space if a != 'split']\n",
    "            return random.choice(available_actions)\n",
    "        state = torch.FloatTensor(state)\n",
    "        act_values = self.model(state)\n",
    "        if not state[-1]:\n",
    "            act_values[self.action_space.index('split')] = -float('inf')\n",
    "\n",
    "        action_idx = torch.argmax(act_values).item()\n",
    "        self.action_counts[self.action_space[action_idx]] += 1\n",
    "        return self.action_space[action_idx]\n",
    "\n",
    "    def replay(self):\n",
    "        if len(self.memory) < self.batch_size:\n",
    "            return\n",
    "        minibatch = random.sample(self.memory, self.batch_size)\n",
    "        for state, action_idx, reward, next_state, done in minibatch:\n",
    "            target = reward\n",
    "            if not done:\n",
    "                next_state = torch.FloatTensor(next_state)\n",
    "                target += self.gamma * torch.max(self.model(next_state)).item()\n",
    "            state = torch.FloatTensor(state)\n",
    "            target_f = self.model(state).detach()\n",
    "            target_f[action_idx] = target\n",
    "            self.optimizer.zero_grad()\n",
    "            loss = self.criterion(self.model(state), target_f)\n",
    "            loss.backward()\n",
    "            self.optimizer.step()\n",
    "        if self.epsilon > self.epsilon_min:\n",
    "            self.epsilon *= self.epsilon_decay\n",
    "\n",
    "    def load_model(self, name):\n",
    "        self.model.load_state_dict(torch.load(name))\n",
    "\n",
    "    def save_model(self, name):\n",
    "        torch.save(self.model.state_dict(), name)\n",
    "\n",
    "\n",
    "class DQNBlackjackEnvironment:\n",
    "    def __init__(self, model_path):\n",
    "        self.suits = ('hearts', 'diamonds', 'clubs', 'spades')\n",
    "        self.ranks = {\n",
    "            'two': 2,\n",
    "            'three': 3,\n",
    "            'four': 4,\n",
    "            'five': 5,\n",
    "            'six': 6,\n",
    "            'seven': 7,\n",
    "            'eight': 8,\n",
    "            'nine': 9,\n",
    "            'ten': 10,\n",
    "            'jack': 10,\n",
    "            'queen': 10,\n",
    "            'king': 10,\n",
    "            'ace': 11\n",
    "        }\n",
    "\n",
    "        # Load the trained model\n",
    "        self.model_path = model_path\n",
    "        self.model = self.load_model()\n",
    "\n",
    "        # Initialize the card counter\n",
    "        self.card_counter = CardCounter(model=self.model)\n",
    "        self.deck = self.create_deck()\n",
    "\n",
    "        self._blackjack_wins = 0\n",
    "        self._regular_wins = 0\n",
    "        self._losses = 0\n",
    "        self._draws = 0\n",
    "        self._hits = 0\n",
    "        self._splits = 0\n",
    "        self._stands = 0\n",
    "        self._hand_count = 0\n",
    "        self._active_hand = 0\n",
    "        self._dealer_hand = []\n",
    "        self._player_hands = [[]]\n",
    "        self._dealer_hand_real = []\n",
    "        self._player_hands_real = [[]]\n",
    "        self.reset_deck()\n",
    "\n",
    "    @property\n",
    "    def blackjack_wins(self):\n",
    "        return self._blackjack_wins\n",
    "\n",
    "    @blackjack_wins.setter\n",
    "    def blackjack_wins(self, blackjack_wins):\n",
    "        self._blackjack_wins = blackjack_wins\n",
    "\n",
    "    @property\n",
    "    def regular_wins(self):\n",
    "        return self._regular_wins\n",
    "\n",
    "    @regular_wins.setter\n",
    "    def regular_wins(self, regular_wins):\n",
    "        self._regular_wins = regular_wins\n",
    "\n",
    "    @property\n",
    "    def losses(self):\n",
    "        return self._losses\n",
    "\n",
    "    @losses.setter\n",
    "    def losses(self, losses):\n",
    "        self._losses = losses\n",
    "\n",
    "    @property\n",
    "    def draws(self):\n",
    "        return self._draws\n",
    "\n",
    "    @draws.setter\n",
    "    def draws(self, draws):\n",
    "        self._draws = draws\n",
    "\n",
    "    @property\n",
    "    def hits(self):\n",
    "        return self._hits\n",
    "\n",
    "    @hits.setter\n",
    "    def hits(self, hits):\n",
    "        self._hits = hits\n",
    "\n",
    "    @property\n",
    "    def splits(self):\n",
    "        return self._splits\n",
    "\n",
    "    @splits.setter\n",
    "    def splits(self, splits):\n",
    "        self._splits = splits\n",
    "\n",
    "    @property\n",
    "    def stands(self):\n",
    "        return self._stands\n",
    "\n",
    "    @stands.setter\n",
    "    def stands(self, stands):\n",
    "        self._stands = stands\n",
    "\n",
    "    @property\n",
    "    def hand_count(self):\n",
    "        return self._hand_count\n",
    "\n",
    "    @hand_count.setter\n",
    "    def hand_count(self, hand_count):\n",
    "        self._hand_count = hand_count\n",
    "\n",
    "    @property\n",
    "    def active_hand(self):\n",
    "        return self._active_hand\n",
    "\n",
    "    @active_hand.setter\n",
    "    def active_hand(self, active_hand):\n",
    "        self._active_hand = active_hand\n",
    "\n",
    "    @property\n",
    "    def dealer_hand(self):\n",
    "        return self._dealer_hand\n",
    "\n",
    "    @dealer_hand.setter\n",
    "    def dealer_hand(self, dealer_hand):\n",
    "        self._dealer_hand = dealer_hand\n",
    "\n",
    "    @property\n",
    "    def player_hands(self):\n",
    "        return self._player_hands\n",
    "\n",
    "    @player_hands.setter\n",
    "    def player_hands(self, player_hands):\n",
    "        self._player_hands = player_hands\n",
    "\n",
    "    @property\n",
    "    def dealer_hand_real(self):\n",
    "        return self._dealer_hand_real\n",
    "\n",
    "    @dealer_hand_real.setter\n",
    "    def dealer_hand_real(self, dealer_hand_real):\n",
    "        self._dealer_hand = dealer_hand_real\n",
    "\n",
    "    @property\n",
    "    def player_hands_real(self):\n",
    "        return self._player_hands_real\n",
    "\n",
    "    @player_hands_real.setter\n",
    "    def player_hands_real(self, player_hands_real):\n",
    "        self._player_hands_real = player_hands_real\n",
    "\n",
    "    def load_model(self, use_kan: bool = True):\n",
    "        input_shape = (224, 224, 3)\n",
    "        num_classes = 53  # 53 classes for 53 cards\n",
    "\n",
    "        model = KANCNN(input_shape, num_classes) if use_kan else Sequential([\n",
    "            Conv2D(32, (3, 3), activation='relu', input_shape=input_shape),\n",
    "            MaxPooling2D((2, 2)),\n",
    "            Conv2D(64, (3, 3), activation='relu'),\n",
    "            MaxPooling2D((2, 2)),\n",
    "            Conv2D(128, (3, 3), activation='relu'),\n",
    "            MaxPooling2D((2, 2)),\n",
    "            Flatten(),\n",
    "            Dense(512, activation='relu'),\n",
    "            Dropout(0.5),\n",
    "            Dense(num_classes, activation='softmax')\n",
    "        ])\n",
    "\n",
    "        model.compile(\n",
    "            optimizer='adam',\n",
    "            loss='categorical_crossentropy',\n",
    "            metrics=['accuracy']\n",
    "        )\n",
    "\n",
    "        model.load_weights(self.model_path)  # Load your trained model weights\n",
    "        return model\n",
    "\n",
    "    def create_deck(self):\n",
    "        deck = [(rank, suit) for rank in self.ranks.keys() for suit in self.suits for _ in\n",
    "                range(self.card_counter.n_decks)]\n",
    "        random.shuffle(deck)\n",
    "        return deck\n",
    "\n",
    "    def deal_card(self):\n",
    "        card = self.deck.pop()\n",
    "        self.card_counter.total_cards -= 1\n",
    "        if self.card_counter.total_cards == 0:\n",
    "            self.deck = self.create_deck()\n",
    "            self.card_counter.reset_deck()\n",
    "\n",
    "        img_path = f'./data/test/{card[0]} of {card[1]}/1.jpg'\n",
    "        images = [tf.image.decode_jpeg(tf.io.read_file(img_path), channels=3)]\n",
    "        prob_high, prob_low, prob_neutral, predicted_cards = self.card_counter.count_cards(images=images)\n",
    "        predicted_card = predicted_cards[0]\n",
    "\n",
    "        return card, predicted_card\n",
    "\n",
    "    def calculate_hand_value(self, hand):\n",
    "        value = 0\n",
    "        ace_count = 0\n",
    "        for card in hand:\n",
    "            rank = card[0]\n",
    "            value += self.ranks[rank]\n",
    "\n",
    "            if rank == 'ace':\n",
    "                ace_count += 1\n",
    "\n",
    "        while value > 21 and ace_count:\n",
    "            value -= 10\n",
    "            ace_count -= 1\n",
    "\n",
    "        return value\n",
    "\n",
    "    def reset(self):\n",
    "        self.player_hands = [[]]\n",
    "        self.player_hands_real = [[]]\n",
    "        self.dealer_hand_real = []\n",
    "        self.dealer_hand = []\n",
    "        self.active_hand = 0\n",
    "\n",
    "        first_player_card, first_player_predicted_card = self.deal_card()\n",
    "        first_dealer_card, first_dealer_predicted_card = self.deal_card()\n",
    "        second_player_card, second_player_predicted_card = self.deal_card()\n",
    "        second_dealer_card, second_dealer_predicted_card = self.deal_card()\n",
    "\n",
    "        self.player_hands[self.active_hand].append(first_player_predicted_card)\n",
    "        self.player_hands_real[self.active_hand].append(first_player_card)\n",
    "        self.dealer_hand.append(first_dealer_predicted_card)\n",
    "        self.dealer_hand_real.append(first_dealer_card)\n",
    "        self.player_hands[self.active_hand].append(second_player_predicted_card)\n",
    "        self.player_hands_real[self.active_hand].append(second_player_card)\n",
    "        self.dealer_hand.append(second_dealer_predicted_card)\n",
    "        self.dealer_hand_real.append(second_dealer_card)\n",
    "\n",
    "        return self.get_state()\n",
    "\n",
    "    def reset_deck(self):\n",
    "        self.deck = self.create_deck()\n",
    "        self.card_counter.reset_deck()\n",
    "        self.probabilities = {'High': [5 / 13], 'Low': [5 / 13], 'Neutral': [3 / 13]}\n",
    "\n",
    "    def one_hot_encode_rank(self, rank):\n",
    "        ranks = ['two', 'three', 'four', 'five', 'six', 'seven', 'eight', 'nine', 'ten', 'jack', 'queen', 'king', 'ace']\n",
    "        encoding = [0] * len(ranks)\n",
    "        encoding[ranks.index(rank)] = 1\n",
    "        return encoding\n",
    "\n",
    "    def get_state(self):\n",
    "        player_hand_value = self.calculate_hand_value(self.player_hands[self.active_hand])\n",
    "        dealer_visible_card = self.one_hot_encode_rank(self.dealer_hand[0][0])\n",
    "        usable_a = self.usable_ace(self.player_hands[self.active_hand])\n",
    "        return [player_hand_value] + dealer_visible_card + [usable_a] + [self.probabilities['High'][-1], self.probabilities['Low'][-1], self.probabilities['Neutral'][-1], self.can_split()]\n",
    "\n",
    "    def can_split(self):\n",
    "        return len(self.player_hands[self.active_hand]) == 2 and self.player_hands[self.active_hand][0][0] == self.player_hands[self.active_hand][1][0]\n",
    "\n",
    "    def usable_ace(self, hand):\n",
    "        return 1 in [card[0] == 'ace' for card in hand] and self.calculate_hand_value(hand) + 10 <= 21\n",
    "\n",
    "    def step(self, action):\n",
    "        if action == 'hit':\n",
    "            self.hits += 1\n",
    "            card, predicted_card = self.deal_card()\n",
    "            self.player_hands_real[self.active_hand].append(card)\n",
    "            self.player_hands[self.active_hand].append(predicted_card)\n",
    "            player_value = self.calculate_hand_value(self.player_hands_real[self.active_hand])\n",
    "            if player_value > 21:\n",
    "                self.losses += 1\n",
    "                reward = -1\n",
    "                done = True\n",
    "                return self.get_state(), reward, done\n",
    "            elif player_value == 21:\n",
    "                self.blackjack_wins += 1\n",
    "                reward = 1.5\n",
    "                done = True\n",
    "                return self.get_state(), reward, done\n",
    "            else:\n",
    "                return self.get_state(), 0, False\n",
    "\n",
    "        elif action == 'stand':\n",
    "            self.stands += 1\n",
    "            if self.active_hand < len(self.player_hands) - 1:\n",
    "                self.active_hand += 1\n",
    "                reward = 0\n",
    "                done = False\n",
    "                return self.get_state(), reward, done\n",
    "\n",
    "            while self.calculate_hand_value(self.dealer_hand_real) < 17:\n",
    "                card, predicted_card = self.deal_card()\n",
    "                self.dealer_hand.append(predicted_card)\n",
    "                self.dealer_hand_real.append(card)\n",
    "\n",
    "            dealer_value = self.calculate_hand_value(self.dealer_hand_real)\n",
    "            rewards = 0\n",
    "            for hand in self.player_hands_real:\n",
    "                player_value = self.calculate_hand_value(hand)\n",
    "                if player_value == 21:\n",
    "                    rewards += 1.5\n",
    "                    self.blackjack_wins += 1\n",
    "                elif player_value < dealer_value <= 21:\n",
    "                    rewards -= 1\n",
    "                    self.losses += 1\n",
    "                elif dealer_value > 21 or player_value > dealer_value:\n",
    "                    rewards += 1\n",
    "                    self.regular_wins += 1\n",
    "                elif player_value == dealer_value and player_value < 21:\n",
    "                    self.draws += 1\n",
    "\n",
    "            done = True\n",
    "            return self.get_state(), rewards, done\n",
    "\n",
    "\n",
    "        elif action == 'split' and len(self.player_hands_real[self.active_hand]) == 2 and self.player_hands_real[self.active_hand][0][0] == self.player_hands_real[self.active_hand][1][0]:\n",
    "            self.splits += 1\n",
    "            first_card, first_predicted_card = self.deal_card()\n",
    "            second_card, second_predicted_card = self.deal_card()\n",
    "            new_hand = [self.player_hands[self.active_hand].pop()]\n",
    "            new_real_hand = [self.player_hands_real[self.active_hand].pop()]\n",
    "\n",
    "            self.player_hands_real[self.active_hand].append(first_card)\n",
    "            self.player_hands[self.active_hand].append(first_predicted_card)\n",
    "            new_hand.append(second_predicted_card)\n",
    "            new_real_hand.append(second_card)\n",
    "\n",
    "            self.player_hands_real.append(new_real_hand)\n",
    "            self.player_hands.append(new_hand)\n",
    "            reward = 0\n",
    "            done = False\n",
    "            return self.get_state(), reward, done\n",
    "\n",
    "        return self.get_state(), 0, False\n",
    "\n",
    "\n",
    "class DQNBlackjackRL:\n",
    "    def __init__(self, root, agent, environment, train_episodes, test_episodes, cnn_model_path):\n",
    "        self.root = root\n",
    "        self.root.title(\"Blackjack DQN RL Agent\")\n",
    "        self.agent = agent\n",
    "        self.environment = environment\n",
    "        self.train_episodes = train_episodes\n",
    "        self.test_episodes = test_episodes\n",
    "        self._probabilities = {'High': [5 / 13], 'Low': [5 / 13], 'Neutral': [3 / 13]}\n",
    "        self.card_images = []\n",
    "        self.game_log = []\n",
    "        self.training = False\n",
    "\n",
    "        # Get screen width and height\n",
    "        screen_width = self.root.winfo_screenwidth()\n",
    "        screen_height = self.root.winfo_screenheight()\n",
    "\n",
    "        # Set window size as a percentage of screen size\n",
    "        window_width = int(screen_width * 0.95)\n",
    "        window_height = int(screen_height * 0.9)\n",
    "        self.root.geometry(f\"{window_width}x{window_height}\")\n",
    "\n",
    "        # Calculate padding as percentages of screen dimensions\n",
    "        padx = int(screen_width * 0.01)\n",
    "        pady = int(screen_height * 0.01)\n",
    "\n",
    "        # Load the trained model\n",
    "        self.cnn_model_path = cnn_model_path\n",
    "        self.cnn_model = self.load_cnn_model()\n",
    "        self.card_counter = CardCounter(model=self.cnn_model)\n",
    "\n",
    "        # Create frames\n",
    "        self.game_frame = tk.Frame(self.root)\n",
    "        self.game_frame.pack(side=tk.LEFT, padx=10, pady=10)\n",
    "        self.stats_frame = tk.Frame(self.root)\n",
    "        self.stats_frame.pack(side=tk.RIGHT, padx=10, pady=10)\n",
    "\n",
    "        # Create frames\n",
    "        self.game_frame = tk.Frame(self.root)\n",
    "        self.game_frame.pack(side=tk.LEFT, padx=padx, pady=pady, expand=True, fill='both')\n",
    "        self.stats_frame = tk.Frame(self.root)\n",
    "        self.stats_frame.pack(side=tk.RIGHT, padx=padx, pady=pady, expand=True, fill='both')\n",
    "\n",
    "        # Create game widgets\n",
    "        num_columns = 4\n",
    "        self.player_label = tk.Label(self.game_frame, text=\"Player's Hand\")\n",
    "        self.player_label.grid(row=0, column=0, columnspan=num_columns)\n",
    "        self.player_frames = [tk.Frame(self.game_frame) for _ in range(4)]\n",
    "        for idx, frame in enumerate(self.player_frames):\n",
    "            frame.grid(row=1, column=idx, padx=padx, pady=pady, sticky='nsew')\n",
    "\n",
    "        self.dealer_label = tk.Label(self.game_frame, text=\"Dealer's Hand\")\n",
    "        self.dealer_label.grid(row=2, column=0, columnspan=num_columns, pady=(pady * 2, 0))\n",
    "        self.dealer_frame = tk.Frame(self.game_frame)\n",
    "        self.dealer_frame.grid(row=3, column=0, columnspan=num_columns, padx=padx, pady=pady, sticky='nsew')\n",
    "\n",
    "        self.start_button = tk.Button(self.game_frame, text=\"Start Training\", command=self.start_training)\n",
    "        self.start_button.grid(row=4, column=0, padx=padx, pady=pady)\n",
    "        self.stop_button = tk.Button(self.game_frame, text=\"Stop Training\", command=self.stop_training,\n",
    "                                     state=tk.DISABLED)\n",
    "        self.stop_button.grid(row=4, column=1, padx=padx, pady=pady)\n",
    "        self.save_button = tk.Button(self.game_frame, text=\"Save Model\", command=self.save_rl_model)\n",
    "        self.save_button.grid(row=5, column=0, padx=padx, pady=pady)\n",
    "        self.load_button = tk.Button(self.game_frame, text=\"Load Model\", command=self.load_rl_model)\n",
    "        self.load_button.grid(row=5, column=1, padx=padx, pady=pady)\n",
    "\n",
    "        self.test_button = tk.Button(self.game_frame, text=\"Test Agent\",\n",
    "                                     command=lambda: self.test_agent(games=test_episodes), state=tk.DISABLED)\n",
    "        self.test_button.grid(row=6, column=0, columnspan=num_columns, pady=pady)\n",
    "\n",
    "        # Create stats widgets with adjusted sizes\n",
    "        fig_width = window_width / 3 / 100\n",
    "        fig_height = window_height / 3 / 100\n",
    "\n",
    "        # Create stats widgets\n",
    "        self.cumulative_rewards_fig, self.cumulative_rewards_ax = plt.subplots(figsize=(fig_width, fig_height))\n",
    "        self.cumulative_rewards_canvas = FigureCanvasTkAgg(self.cumulative_rewards_fig, master=self.stats_frame)\n",
    "        self.cumulative_rewards_canvas.get_tk_widget().grid(row=0, column=0)\n",
    "\n",
    "        self.average_rewards_fig, self.average_rewards_ax = plt.subplots(figsize=(fig_width, fig_height))\n",
    "        self.average_rewards_canvas = FigureCanvasTkAgg(self.average_rewards_fig, master=self.stats_frame)\n",
    "        self.average_rewards_canvas.get_tk_widget().grid(row=0, column=1)\n",
    "\n",
    "        self.win_loss_fig, self.win_loss_ax = plt.subplots(figsize=(fig_width, fig_height))\n",
    "        self.win_loss_canvas = FigureCanvasTkAgg(self.win_loss_fig, master=self.stats_frame)\n",
    "        self.win_loss_canvas.get_tk_widget().grid(row=1, column=0)\n",
    "\n",
    "        self.prob_fig, self.prob_ax = plt.subplots(figsize=(fig_width, fig_height))\n",
    "        self.prob_canvas = FigureCanvasTkAgg(self.prob_fig, master=self.stats_frame)\n",
    "        self.prob_canvas.get_tk_widget().grid(row=1, column=1)\n",
    "\n",
    "        self.q_values_fig, self.q_values_ax = plt.subplots(figsize=(fig_width, fig_height))\n",
    "        self.q_values_canvas = FigureCanvasTkAgg(self.q_values_fig, master=self.stats_frame)\n",
    "        self.q_values_canvas.get_tk_widget().grid(row=2, column=0)\n",
    "\n",
    "        self.action_counts_fig, self.action_counts_ax = plt.subplots(figsize=(fig_width, fig_height))\n",
    "        self.action_counts_canvas = FigureCanvasTkAgg(self.action_counts_fig, master=self.stats_frame)\n",
    "        self.action_counts_canvas.get_tk_widget().grid(row=2, column=1)\n",
    "\n",
    "        # Create a scrollable text widget for logs\n",
    "        self.log_frame = tk.Frame(self.stats_frame)\n",
    "        self.log_frame.grid(row=3, column=0, columnspan=2, sticky='nsew')\n",
    "        self.log_text = tk.Text(self.log_frame, wrap=tk.WORD, state=tk.NORMAL, width=80, height=10)\n",
    "        self.log_text.pack(side=tk.LEFT, fill=tk.BOTH, expand=True)\n",
    "        self.log_scrollbar = ttk.Scrollbar(self.log_frame, command=self.log_text.yview)\n",
    "        self.log_scrollbar.pack(side=tk.RIGHT, fill=tk.Y)\n",
    "        self.log_text.config(yscrollcommand=self.log_scrollbar.set)\n",
    "\n",
    "        self.episode_count = 0\n",
    "\n",
    "    @property\n",
    "    def probabilities(self):\n",
    "        return self._probabilities\n",
    "\n",
    "    @probabilities.setter\n",
    "    def probabilities(self, probabilities):\n",
    "        self._probabilities = probabilities\n",
    "\n",
    "    def load_cnn_model(self, use_kan: bool = True):\n",
    "        input_shape = (224, 224, 3)\n",
    "        num_classes = 53  # 53 classes for 53 cards\n",
    "\n",
    "        model = KANCNN(input_shape, num_classes) if use_kan else Sequential([\n",
    "            Conv2D(32, (3, 3), activation='relu', input_shape=input_shape),\n",
    "            MaxPooling2D((2, 2)),\n",
    "            Conv2D(64, (3, 3), activation='relu'),\n",
    "            MaxPooling2D((2, 2)),\n",
    "            Conv2D(128, (3, 3), activation='relu'),\n",
    "            MaxPooling2D((2, 2)),\n",
    "            Flatten(),\n",
    "            Dense(512, activation='relu'),\n",
    "            Dropout(0.5),\n",
    "            Dense(num_classes, activation='softmax')\n",
    "        ])\n",
    "\n",
    "        model.compile(\n",
    "            optimizer='adam',\n",
    "            loss='categorical_crossentropy',\n",
    "            metrics=['accuracy']\n",
    "        )\n",
    "\n",
    "        model.load_weights(self.cnn_model_path)  # Load your trained model weights\n",
    "        return model\n",
    "\n",
    "    def save_rl_model(self):\n",
    "        file_path = filedialog.asksaveasfilename(defaultextension=\".h5\",\n",
    "                                                 filetypes=[(\"H5 files\", \"*.h5\"), (\"PKL files\", \"*.pkl\"),\n",
    "                                                            (\"All files\", \"*.*\")])\n",
    "        if file_path:\n",
    "            self.agent.save_model(file_path)\n",
    "            print(f\"Model saved to: {file_path}\")\n",
    "\n",
    "    def load_rl_model(self):\n",
    "        file_path = filedialog.askopenfilename(\n",
    "            filetypes=[(\"H5 files\", \"*.h5\"), (\"PKL files\", \"*.pkl\"), (\"All files\", \"*.*\")])\n",
    "        if file_path:\n",
    "            self.agent.load_model(file_path)\n",
    "            print(f\"Model loaded from: {file_path}\")\n",
    "\n",
    "    def display_hand(self, hand, frame, is_dealer=True):\n",
    "        for widget in frame.winfo_children():\n",
    "            widget.destroy()\n",
    "\n",
    "        for i, card in enumerate(hand):\n",
    "            img_path = f'./data/test/{card[0]} of {card[1]}/1.jpg'\n",
    "\n",
    "            # Debugging: Check if the image path exists\n",
    "            if not os.path.exists(img_path):\n",
    "                print(f\"Image path does not exist: {img_path}\")\n",
    "                continue\n",
    "\n",
    "            images = [tf.image.decode_jpeg(tf.io.read_file(img_path), channels=3)]\n",
    "            prob_high, prob_low, prob_neutral, predicted_cards = self.card_counter.count_cards(images=images)\n",
    "            predicted_card = predicted_cards[0]\n",
    "            predicted_img_path = f'./data/test/{predicted_card[0]} of {predicted_card[1]}/1.jpg'\n",
    "\n",
    "            if not os.path.exists(predicted_img_path):\n",
    "                print(f\"Image path does not exist: {predicted_img_path}\")\n",
    "                return\n",
    "\n",
    "            try:\n",
    "                img = Image.open(img_path)\n",
    "                img = img.resize((100, 150), Image.LANCZOS)\n",
    "                photo = ImageTk.PhotoImage(img)\n",
    "                self.card_images.append(photo)  # Keep a reference to the image\n",
    "                label = tk.Label(frame, image=photo)\n",
    "                label.image = photo  # Ensure reference is kept by the label\n",
    "                label.grid(row=0, column=i)\n",
    "                frame_text = f'{card[0]} of {card[1]}'\n",
    "                if is_dealer:\n",
    "                    frame_text = f'Actual: {frame_text}\\nPredicted: {predicted_card[0]} of {predicted_card[1]}'\n",
    "\n",
    "                tk.Label(frame, text=frame_text).grid(row=1, column=i)\n",
    "            except Exception as e:\n",
    "                print(f\"Failed to load image {img_path}: {e}\")\n",
    "\n",
    "        return hand\n",
    "\n",
    "    def update_stats(self):\n",
    "        # Update cumulative rewards plot\n",
    "        cumulative_rewards = np.cumsum(self.agent.rewards)\n",
    "        self.cumulative_rewards_ax.clear()\n",
    "        self.cumulative_rewards_ax.plot(cumulative_rewards, label='Cumulative Reward')\n",
    "        self.cumulative_rewards_ax.set_xlabel('Episode')\n",
    "        self.cumulative_rewards_ax.set_ylabel('Cumulative Reward')\n",
    "        self.cumulative_rewards_ax.set_title('Cumulative Rewards Over Time')\n",
    "        self.cumulative_rewards_ax.legend()\n",
    "        self.cumulative_rewards_canvas.draw()\n",
    "\n",
    "        # Update average rewards plot\n",
    "        average_rewards = cumulative_rewards / (np.arange(len(self.agent.rewards)) + 1)\n",
    "        self.average_rewards_ax.clear()\n",
    "        self.average_rewards_ax.plot(average_rewards, label='Average Reward per Episode')\n",
    "        self.average_rewards_ax.set_xlabel('Episode')\n",
    "        self.average_rewards_ax.set_ylabel('Average Reward')\n",
    "        self.average_rewards_ax.set_title('Average Rewards Over Time')\n",
    "        self.average_rewards_ax.legend()\n",
    "        self.average_rewards_canvas.draw()\n",
    "\n",
    "        # Update win/loss plot\n",
    "        win_data = {\n",
    "            \"Regular Wins\": self.environment.regular_wins,\n",
    "            \"Blackjack Wins\": self.environment.blackjack_wins,\n",
    "            \"Losses\": self.environment.losses,\n",
    "            \"Draws\": self.environment.draws\n",
    "        }\n",
    "        self.win_loss_ax.clear()\n",
    "        self.win_loss_ax.bar(win_data.keys(), win_data.values())\n",
    "        self.win_loss_ax.set_title(\"Wins, Losses, Draws\")\n",
    "        self.win_loss_ax.set_ylabel(\"Count\")\n",
    "        self.win_loss_canvas.draw()\n",
    "\n",
    "        # Update probability plot\n",
    "        prob_data = {\n",
    "            \"High\": self.probabilities[\"High\"][-1],\n",
    "            \"Low\": self.probabilities[\"Low\"][-1],\n",
    "            \"Neutral\": self.probabilities[\"Neutral\"][-1]\n",
    "        }\n",
    "        self.prob_ax.clear()\n",
    "        self.prob_ax.bar(prob_data.keys(), prob_data.values())\n",
    "        self.prob_ax.set_title(\"Card Probabilities\")\n",
    "        self.prob_ax.set_ylabel(\"Count\")\n",
    "        self.prob_canvas.draw()\n",
    "\n",
    "        # Update Q-values plot\n",
    "        state = self.environment.get_state()\n",
    "        q_values = self.agent.model(torch.FloatTensor(state)).detach().numpy()\n",
    "        if not state[-1]:\n",
    "            q_values[self.agent.action_space.index('split')] = 0\n",
    "\n",
    "        self.q_values_ax.clear()\n",
    "        self.q_values_ax.bar(self.agent.action_space, q_values)\n",
    "        self.q_values_ax.set_xlabel('Actions')\n",
    "        self.q_values_ax.set_ylabel('Q-values')\n",
    "        self.q_values_ax.set_title('Q-values for Current State')\n",
    "        self.q_values_canvas.draw()\n",
    "\n",
    "        # Update action counts plot\n",
    "        actions = list(self.agent.action_counts.keys())\n",
    "        counts = list(self.agent.action_counts.values())\n",
    "        self.action_counts_ax.clear()\n",
    "        self.action_counts_ax.bar(actions, counts)\n",
    "        self.action_counts_ax.set_xlabel('Actions')\n",
    "        self.action_counts_ax.set_ylabel('Counts')\n",
    "        self.action_counts_ax.set_title('Action Selection Frequency')\n",
    "        self.action_counts_canvas.draw()\n",
    "\n",
    "    def log_message(self, message):\n",
    "        self.game_log.append(message)\n",
    "        self.log_text.config(state=tk.NORMAL)\n",
    "        self.log_text.insert(tk.END, message + \"\\n\")\n",
    "        self.log_text.config(state=tk.NORMAL)\n",
    "        self.log_text.yview(tk.END)\n",
    "\n",
    "    def start_training(self):\n",
    "        self.training = True\n",
    "        self.start_button.config(state=tk.DISABLED)\n",
    "        self.stop_button.config(state=tk.NORMAL)\n",
    "        self.test_button.config(state=tk.DISABLED)\n",
    "        self.train_agent()\n",
    "\n",
    "    def stop_training(self):\n",
    "        self.training = False\n",
    "        self.start_button.config(state=tk.NORMAL)\n",
    "        self.stop_button.config(state=tk.DISABLED)\n",
    "        self.test_button.config(state=tk.NORMAL)\n",
    "\n",
    "    def reset_game(self):\n",
    "        self.environment.reset()\n",
    "        for frame in self.player_frames:\n",
    "            for widget in frame.winfo_children():\n",
    "                widget.destroy()\n",
    "        for widget in self.dealer_frame.winfo_children():\n",
    "            widget.destroy()\n",
    "\n",
    "        self.update_stats()\n",
    "\n",
    "    def train_agent(self):\n",
    "        if not self.training:\n",
    "            return\n",
    "\n",
    "        self.reset_game()\n",
    "        state = self.environment.reset()\n",
    "        done = False\n",
    "        while not done:\n",
    "            self.root.update_idletasks()\n",
    "            self.root.update()\n",
    "            action = self.agent.act(state)\n",
    "            next_state, reward, done = self.environment.step(action)\n",
    "            self.agent.remember(state, action, reward, next_state, done)\n",
    "            self.agent.replay()\n",
    "            state = next_state\n",
    "            self.update_hand_display()\n",
    "            if done:\n",
    "                self.episode_count += 1\n",
    "                self.agent.rewards.append(reward)\n",
    "                self.update_stats()\n",
    "                self.log_message(f\"Episode {self.episode_count}: Reward {reward}\")\n",
    "                self.root.after(1000, self.train_agent)\n",
    "                break\n",
    "\n",
    "            self.root.after(1000, lambda: None)  # Add delay for visualization\n",
    "\n",
    "    def update_hand_display(self):\n",
    "        for idx, hand in enumerate(self.environment.player_hands_real):\n",
    "            self.display_hand(hand, self.player_frames[idx])\n",
    "\n",
    "        self.display_hand(self.environment.dealer_hand_real, self.dealer_frame, is_dealer=True)\n",
    "\n",
    "    def test_agent(self, games=100):\n",
    "        wins, losses, draws = 0, 0, 0\n",
    "        for _ in range(games):\n",
    "            state = self.environment.reset()\n",
    "            done = False\n",
    "            while not done:\n",
    "                action = self.agent.act(state)\n",
    "                next_state, reward, done = self.environment.step(action)\n",
    "                state = next_state\n",
    "                if done:\n",
    "                    if reward == 1:\n",
    "                        wins += 1\n",
    "                    elif reward == -1:\n",
    "                        losses += 1\n",
    "                    else:\n",
    "                        draws += 1\n",
    "\n",
    "        messagebox.showinfo(\"Test Results\",\n",
    "                            f\"Results over {games} games:\\nWins: {wins}\\nLosses: {losses}\\nDraws: {draws}\")\n",
    "\n",
    "    def start(self):\n",
    "        self.root.mainloop()"
   ],
   "id": "8de4d05b458df3f2"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Calculate the state size based on the returned state from get_state method\n",
    "player_hand_value_size = 1\n",
    "dealer_visible_card_size = 13  # One-hot encoding of 13 ranks\n",
    "usable_ace_size = 1\n",
    "probabilities_size = 3\n",
    "split_possibility_indicator = 1\n",
    "\n",
    "state_size = player_hand_value_size + dealer_visible_card_size + usable_ace_size + probabilities_size + split_possibility_indicator\n",
    "actions = ['hit', 'stand', 'split']\n",
    "\n",
    "env = DQNBlackjackEnvironment(model_path=model_path)\n",
    "agent = DQNAgent(state_size=state_size, action_space=actions)\n",
    "\n",
    "# Create and start the GUI\n",
    "dqn_root = tk.Tk()\n",
    "dqn_app = DQNBlackjackRL(\n",
    "    root=dqn_root,\n",
    "    agent=agent,\n",
    "    environment=env,\n",
    "    train_episodes=1000,\n",
    "    test_episodes=100,\n",
    "    cnn_model_path=model_path\n",
    ")\n",
    "\n",
    "dqn_app.start()"
   ],
   "id": "d21cea7409be4a9"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "df4b96ac6e1d0604"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
